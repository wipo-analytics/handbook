[
["index.html", "The WIPO Patent Analytics Handbook Note to Readers", " The WIPO Patent Analytics Handbook Paul Oldham 2018-09-24 Note to Readers This is the working draft of the forthcoming WIPO Patent Analytics Handbook. The Handbook is being written in the open and is presently incomplete. New chapters will be added as they become available. If you would like to correct or comment on entries in the Handbook please raise an issue on Github here. Alternatively please email poldham at mac dot com or irene dot kitsara at wipo dot int. Comments, corrections and suggestions for improvement are very welcome in ensuring the Handbook is a useful resources for the wider community. "],
["about-the-author.html", "About the Author", " About the Author The Handbook was written by Paul Oldham with contributions by Irene Kitsara. Paul Oldham holds a Ph.D from the London School of Economics and Political Science and is the Director of One World Analytics. He is an Industrial Fellow at the Manchester Institute of Innovation Research, Manchester Business School and a Senior Visiting Fellow at the Institute for the Advanced Study of Sustainability at United Nations University. Irene Kitsara is an Intellectual Property Lawyer who formerly worked with Deloitte and a Patent Analytics expert. She is presently an Intellectual Property Information Officer at WIPO with responsibility for the preparation of Patent Landscape reports and … "],
["acknowlegements.html", "Acknowlegements", " Acknowlegements The WIPO Patent Analytics Handbook is being written with the generous financial support of the Patent Office of Japan (JPO). The Handbook is being prepared under the direction of Mr. Yo Takagi (Assistant Director General) and under the supervision of Mr. Alejandro Roca Campaña (Senior Director) and Mr. Andrew Czajkowski (Head of Section). Irene Kitsara (IP Information Officer) coordinated the preparation and review of the Handbook. "],
["preface.html", "Preface", " Preface The WIPO Patent Analytics Handbook provides a guide to advanced methods for patent analytics. The Handbook builds on the WIPO Manual for Open Source Patent Analytics which provided an introduction to working with patent data using a range of free tools to obtain, clean and visualize patent data. The handbook aims to address two challenges. The first of these challenges is that anyone seeking to start work in patent analytics is confronted by the challenge that there is a lack of a source of practical guidance on how to develop descriptive patent statistics. The OECD Patent Statistics Manual is required reading for anyone seeking to engage with patent statistics and is an invaluable resource (OECD Patent Statistics Manual 2009). However, it focuses on the issues we need to think about rather than practical demonstration. The Handbook addresses this problem by moving from first principles in the development of patent counts for descriptive statistics to the basics of statistical models for forecasting patent trends. In the process the Handbook build a bridge to more sophisticated approaches to working with patent data at scale in fields such as econometrics and points to important resources in these areas. The ability to generate descriptive patent statistics and statistical models is only one aspect of patent analytics. Recent years have witnessed an explosion in the availability of different data types that can be integrated with patent data to better inform and enrich analysis. The second and major challenge addressed by the Handbook is integrating different data types from the scientific literature, to geographic information and the results of text mining into patent analytics. In turn the range of methods that are available to patent analysts for working with patent data promises to be transformed by the emergence of accessible machine learning tools for use across a range of topics such as applicant name cleaning, text mining and image classification. In common with many other fields of research the emergence of machine learning appears to hold considerable promise for patent analytics but it remains to be seen whether this promise will be realised. The Handbook is therefore intended to be used by researchers and professionals who are relatively new to working with patent data. It is also intended to be of interest for experienced researchers and professionals who are interested in expanding their skills in working with patent and related data. One important challenge that has emerged in recent years with the growth of patent analytics and patent landscape analysis is the problem of reproducibility (???). Patent analysts typically work with data from a number of different databases and use a number of different methods in their analysis. However, the precise details of the coverage of different sources, the methods used, and the limitations of different approaches are often not made explicit. This makes it difficult for other to reproduce the results and to assess the quality of the analysis presented. The Handbook takes the approach that patent analysis should be reproducible. The Handbook addresses this issue by using examples from standardised open access datasets created for this purpose. The online version of the Handbook is accompanied by the code used to develop the examples. References "],
["how-to-use-the-handbook.html", "How to use the Handbook", " How to use the Handbook This Handbook consists of self standing chapters on different topics and is intended to be used in two ways. It can be used as a reference guide to a topic with worked examples for illustration and key literature sources to guide further reading on a topic. The Handbook can also be used as practical guide by downloading the datasets and reproducing the worked examples to help you apply the methods to your own analysis. Patent analytics involves a wide range of skills across different disciplines and one aim of the Handbook is to point to important sources of further information and training for each topic. If you wish to reproduce the examples please use the following instructions. The handbook and its examples were written mainly in RStudio. RStudio is an easy to use and powerful platform for patent analytics and preparing data and reports for publication. To use RStudio you need to start by installing R for your operating system by visiting this http://cran.rstudio.com/. We will use the free version of RStudio that can be downloaded https://www.rstudio.com/products/rstudio/download/. This Handbook is open access and each chapter and the code used to develop the examples can be downloaded free of charge from Github at https://github.com/wipo-analytics/handbook. The Handbook can be opened in RStudio using the handbook.Rproj file. The Handbook makes use of a number of R packages. To install all packages used in the Handbook run the following lines in the console:{r eval=FALSE} install.packages(&quot;tidyverse&quot;) install.packages(&quot;rcrossref&quot;) install.packages(&quot;rorcid&quot;) install.packages(&quot;leaflet&quot;) install.packages(&quot;forecast&quot;) install.packages(&quot;tidytext&quot;) install.packages(&quot;devtools&quot;) install.packages(&quot;usethis&quot;) To load the libraries use: library(tidyverse) library(rcrossref) library(rorcid) library(leaflet) library(forecast) library(tidytext) library(devtools) library(usethis) 0.0.1 Datasets The drones dataset. This is a set of training datasets used in examples. The core dataset consists of 15,557 patent applications involving the term drone or drones somewhere in the text. You can download the data as a zip file from github at https://github.com/wipo-analytics/drones Users of Rstudio can install the drones package directly using the following code. Note that the devtools package must be installed (included in the packages above). devtools::install_github(&quot;wipo-analytics/drones&quot;) When the drones package is installed review the contents of each dataset in the package documentation (see Packages in Rstudio) and load the data into your workspace using the following. drones &lt;- drones::drones "],
["introduction.html", "Chapter 1 Introduction", " Chapter 1 Introduction Patent analytics is a growing field that encompasses the analysis of patent data, analysis of the scientific literature, data cleaning, text mining, machine learning, geographic mapping and data visualisation. The WIPO Patent Analytics Handbook provides an introduction to advanced methods and tools for patent analytics. The Handbook complements the WIPO Manual on Open Source Patent Analytics which provides an introduction to tools and methods in patent analytics. The Handbook focuses on more advanced methods and approaches using commercial and free tools and databases. The fields of patent search, patent statistics and patent analytics have been transformed in recent years by the growing availability of free and commercial databases and software for data mining, data visualisation and geographic mapping. The increasing availability of a wide range of web services or Application Programming Interfaces for access to patent data, the scientific literature and cloud computing services for machine learning or geocoding mean that today a patent analyst has access to an unprecedented and cost effective range of tools to facilitate their work. Chapter 2 focuses on researching the scientific literature as a foundation for in depth patent research and analysis. This chapter begins by highlighting the growing accessibility of scientific publcations and data arising from an increasing emphasis on open access publication. The chapter then focuses on the role of exploratory searches of the scientific literature in defining key word search strategies. The chapter then explores the main issues that arise when working with the scientific literature and how they can be addressed. The chapter concludes by considering strategies for joining together the scientific literature and patent literature. Chapter 3 addresses methods for counting patent data as a basis for creating descriptive patent statistics and statistical models. Methodologies for patent counts has received remarkably little attention outside a highly specialised literature and this chapter aims to provide a step by step introduction to the issues involves in developing descriptive patent statistics. The chapter concludes by illustrating how trends in demand for patent rights can be identified across multiple countries. Chapter 4 focuses on the EPO World Patent Statistical Database as the tool used by many patent offices and researchers as the international standard for the development of patent statistics and indicators. In common with other databases PATSTAT requires the use of the SQL language to generate queries or interfaces such as IISC PATSTAT that make access to PATSTAT easier Chapter 5 addresses the use of other patent datafields such as applicant and inventor names, classification codes and citation data in the development of innovation analysis and business intelligence indicators. Chapter 6 provides an introduction to text mining as a powerful tool in the patent analysts toolbox. Building on the discussion in Chapter 1 the chapter moves through the basics of text mining with patent data and concludes with a growing emphasis on machine learning approaches such as the popular Word2Vec algorithm. Chapter 7 geocoding of patent data to develop geographic maps of patent and related data to geographic maps. Increasingly, it is possible to link different types of data on the same map using online geolocation services and to present the results in interactive maps. This chapter will discuss the principal patent data fields that are available for mapping and provide illustrations from services such as the USPTO and the ASEAN marine patent landscape report. The strengths and weaknesses of geolocation services such as the Google Maps API will be discussed such as the noisy nature of patent names and address fields, methods for regularising address data and the challenges involved in validating the georeferenced data returned from geolocation web services. Chapter 9 focuses on the opportunities presented by machine learning to advance patent analytics. Machine learning or artificial intelligence approaches are increasingly being applied to text classification and named entity recognition and image classification. The application of machine learning in patent analytics remains at an early stage with the USPTO pioneering the application of machine learning algorithms to inventor and applicant name cleaning while Clarivate Analytics has recently applied machine learning to enhance the cleaning of applicant names. In future years we are likely to see the application of machine learning across the spectrum of patent analysis tasks. However, it can be very difficult to separate the hype around machine learning and artificial intelligence from the reality of what is available and achievable now. This chapter aims to assist with navigating these exciting but at times confusing and over hyped opportunities. The patent system is supported by a range of classification schemes that are designed to assist patent examiners with identifying and retrieving patent documents. These classsfication schemes commonly take the form of alphanumeric codes organised from general to specific categories. Chapter 10 discusses the use of the International Patent Classification (IPC) and the closely related Cooperative Patent Classification (CPC) in patent analytics. Chapter 11 discusses the important role that patent citations play in patent analytics and the strengths and weaknesses of different approaches to patent citation analysis. The chapter begins with a description of the two types of patent citation (backwards and forward citations), the sources of patent citations and their impacts before considering different approaches to citation counts based on citations of individual documents and citations of patent families. Chapter 12 considers the emerging topic of social media as part of the toolbox for patent analytics. Using data from Twitter as an example, the chapter considers the potential use of social media data in areas such as searching for prior art, understanding company activity in a technology, assessing potential markets for an invention and public debate around controversial areas of science and technology such as artificial intelligence. "],
["literature.html", "Chapter 2 Scientific Literature 2.1 Accessing the Scientific Literature 2.2 Searching Literature Databases 2.3 Precision vs. Recall 2.4 Processing Scientific Literature 2.5 Visualizing the Scientific Literature 2.6 Linking the Scientific Literature with Patent Analysis 2.7 Linking Citations with Patent Literature 2.8 Conclusion", " Chapter 2 Scientific Literature This chapter examines the role of research involving the scientific literature and patent analytics. Analysis of scientific literature is a specialised field in its own right in the form of bibliometrics or scientometrics with its own specialist journals such as Scientometrics and other publications (Ball 2018). These fields cover a wide range of topics involving statistical analysis of scientific literature such as indicators for science and technology, exploration of the impacts of scientific research, research networks, and the mobility of researchers. These field are characterised by a combination of qualitative and quantitative methods and are frequently oriented towards the understanding of trends in science and technology to inform research and innovation policies. The relationship between science and technological innovation is an important focus of research and links analysis of the scientific literature with patent literature. This chapter focuses on the how analysis of the scientific literature can inform patent analytics in there main ways: By informing search strategies By identifying actors who are active inside or outside the scientific literature as part of landscape analysis. Identifying potential opportunities for economic development to address the needs of developing countries. We will begin with a brief overview of ways to access the scientific literature before turning to a discussion of scientific data fields using data from Clarivate Analytics Web of Science as an example. We will then explore how the scientific literature can be used to inform search strategies through the identification of terms from the scientific literature for use in patent searches. We will then look at methods for matching actors from the scientific literature into the patent literature using data from ASEAN countries as an example. Finally, we will look at how comparisons between the scientific literature and the patent literature can assist developing countries with identifying opportunities for economic development to address their needs. 2.1 Accessing the Scientific Literature The main means for accessing the scientific literature is through databases of scientific literature and increasingly through open access databases using web services of application programming interfaces (APIs). Researchers based in Universities will generally be familiar with two of the largest of the commercial databases of the scientific literature, Web of Science/Web of Knowledge from Clarivate Analytics or Elsevier’s Scopus. Open access databases such as PubMed and Crossref (containing metadata on over 96 million publications) are increasingly popular and link to initiatives such as core.ac.uk that, at the time of writing, make the full texts of over 113 million publications publicly available. Databases such as Google Scholar are a popular open access source of information on the scientific literature and access to copies of texts while social network sites for researchers such as Research Gate provides a means for scholars to share their research and create shared projects. An important feature of recent developments in scientific publication is a shift in emphasis towards open access publications on the part of researchers and funding agencies. This is reflected in services such as core.ac.uk noted above and in services such as Unpaywall which provides a browser plugin to identify open access versions of articles. At present Unpaywall contains links to over 19 million scientific publications. An important aspect of this shift in emphasis towards open access is cross service integration. Thus Unpaywall is based on and resolves article identifiers to the content of Crossref while the commercial Web of Science database provides links to Unpaywall in its results to allow free retrieval of articles. Other important emerging services include tools such as Open Academic Graph which provides access to meta data on over 330 million publications. As this makes clear the landscape for accessing scientific literature is changing as a result of the rise of web service enabled database and cross-service integration tools. In practical terms this means that access to the scientific literature is no longer entirely dependent on fee based databases. It is important to emphasise that publication databases normally have strengths and weaknesses in terms of: Coverage of journals, books and other publications The languages covered and availability of translations The range of fields available for analysis (authors, affiliations, titles, abstracts etc.) The basis of any statistical counts (e.g. counts of citing articles) The number of records that can be downloaded The format in which records can be downloaded These issues impose constraints on what can be searched and downloaded from scientific databases. For example, in our experience Web of Science permits for the downloaded of a wider range of data fields than Scopus, while open access databases enjoy the advantage of being free but are more limited in terms of the data fields that are available and the consistency of coverage, such as abstracts. When seeking to carry out literature research as part of a wider patent analytics project it is therefore important to consider the strengths and weaknesses of particular databases and to use multiple sources where necessary. 2.2 Searching Literature Databases 2.2.1 Stemming When searching a literature database it is important as a first step to understand the available search fields and search operators (such as OR and AND). Many databases now offer what is called word “stemming” that will look for similar words or phrases based on the root of the terms used during input… for example if we input the word “drone”, a stemmed version based on the root “drone” would include words like “drones”, “droned” and “droning”. In technical terms words like “drones”. “droned” and “droning” are lemmas. Word stemming is a powerful tool for expanding the range of searches and can be extended to using synonyms. Specialist tools such as WordNet, a lexical database of English words and synonyms, can be used to identify synonyms on a search term (Fellbaum 2015). WordNet can be used in a range of programming languages or using the free online tool. The results of a search of WordNet for the word Drone are presented below: Noun S: (n) drone (stingless male bee in a colony of social bees (especially honeybees) whose sole function is to mate with the queen) S: (n) monotone, drone, droning (an unchanging intonation) S: (n) dawdler, drone, laggard, lagger, trailer, poke (someone who takes more time than necessary; someone who lags behind) S: (n) drone, pilotless aircraft, radio-controlled aircraft (an aircraft without a pilot that is operated by remote control) S: (n) drone, drone pipe, bourdon (a pipe of the bagpipe that is tuned to produce a single continuous tone) Verb S: (v) drone (make a monotonous low dull sound) “The harmonium was droning on” S: (v) drone, drone on (talk in a monotonous voice) The use of a stemming tool helps to reveal the range of possible uses of a search term. In the case of the word drone we can see references to bees, to sound, to a part of a musical instrument and for pilotless aircraft. The range of the uses of these terms suggests a need for caution. Thus the use of the term drone in a scientific database is likely to return results on all of these potential uses of the work drone. Stemming algorithms can both aid and hinder information retrieval. For example, if stemming is automatically turned on then the word “droning” would automatically be included and thus populate the results with data on the irrelevant subject of sound for those interested in drone technology. In contrast, where the stemming tool displays synonyms we might wish to include pilotless aircraft in the original search. In practice, when initiating a search of a database of the scientific literature on an unfamiliar subject it is generally best to turn off stemming and to focus on downloading a test set of results for review. The aim here is to use a limited set of terms to identify other potentially relevant terms and terms that can be excluded from a sample. This approach can be used with a wide range of software tools, including simple tools such as Excel or free online tools. The objective is to take available fields such as the title, abstract, and author keywords and to break them down into their constituent words and phrases. This is a process known as tokenizing text fields into words, phrases (ngrams), sentences and paragraphs of various lengths and is a fundamental feature of computational linguistics, text mining and machine learning [refs]. We will look in greater detail at text mining in Chapter 6. One powerful tool in working with both scientific and patent data is VantagePoint from Search Technology Inc. VantagePoint is available in a student edition and 32 and 64 bit versions for Windows. VantagePoint is able to import a wide range of different data sources and automatically tokenize text fields into words and phrases. Table 2.1 below presents the combined top 50 terms in the titles, abstracts, and author keywords from a search of Web of Science for the words drone or drones between 2010 and 2017. Table 2.1: Top Words and Phrases for Drones in Web of Science records terms multi_word 479 drones 0 241 drone 0 240 results 0 181 study 0 170 use 0 141 article 0 126 rights reserved 1 91 number 0 89 queens 0 88 development 0 87 workers 0 86 Apis mellifera 1 85 data 0 85 UAV 0 84 one 0 81 colonies 0 69 analysis 0 62 time 0 60 first 0 56 effects 0 When we inspect the results in Table 2.1 we see a full list of words and phrases. Many of these will not be relevant to drones as such, for example the words article or study and common noisy terms such as “and, or, of, for” are commonly excluded as stop words. In other cases references to the word “queens” or its root “queen” along with “Apis mellifera” and “colonies” suggests that we have a lot of data on bees in the data. In our next iteration of the search we would probably want to explicitly exclude these terms from the search. However we can also detect other works that we might want to include in our search such as “UAV” for Unmanned Aerial Vehicle. In practice multi word phrases (ngrams) commonly express concepts (ref Mogatov?) and bring us closer to the terms that we will want to use in a search. Table 2.2 ranks the data based on multi-word phrases. Table 2.2: Top Phrases in Web of Science Data on Drones records terms multi_word 126 rights reserved 1 86 Apis mellifera 1 50 honey bee 1 49 unmanned aerial vehicles 1 44 honey bees 1 42 Unmanned Aerial Vehicles (UAVs) 1 40 United States 1 32 remote sensing 1 29 unmanned aerial vehicle (UAV) 1 28 unmanned aerial vehicle 1 28 Varroa destructor 1 25 drone strikes 1 24 recent years 1 23 Elsevier Ltd 1 22 experimental results 1 20 drone warfare 1 20 present study 1 479 drones 0 241 drone 0 240 results 0 Table 2.2 reveals irrelevant phrases such as “honey bee” and its plural “honey bees” along with Varroa destructor, a mite that parasatises bees. We also observe the prevalence of unmanned aerial vehicles and their plurals linked to the term UAV and applications of drone technology such as “drone warfare” and “drone strikes”. A review of the terms captured in initial exploratory research can thus go a long way to refining a search strategy to improve and focus recall and precision (refs). We have focused here on the top terms in the data. However, in other cases it may be appropriate to review the full list to identify low frequency but highly relevant terms. This type of task can be approached computationally for example by creating a matrix of terms linked to a specific term [example Unmanned Aerial Vehicle] to capture closely related terms. As an alternative the use of the Term Frequency Inverse Document Frequency algorithm (TFIDF). This is an extremely popular calculation that weights terms based on how important they are to the set of documents in the corpus. The key idea behind Inverse Document Frequency comes from Karen Spark Jones in 1972 who proposed that: “…terms should be weighted according to collection frequency, so that matches on less frequent, more specific, terms are of greater value than matches on frequent terms.”(Jones 1972, @Robertson_2004). In other words using TFIDF high frequency words such as “the” or “and” receive lower weightings than document specific terms such as “unmanned aerial vehicle” that distinguish documents from the wider set. The TFIDF algorithm is extremely widely used in information retrieval and is built in to tools such as VantagePoint. In practice, the use of matrices to identify nearby words and phrases or TFIDF may not be necessary and will depend on how specific your topic search may be. Other more recent methods such as Word2Vec will be considered in greater detail in Chapter 6 2.2.2 Using Search Operators Many databases include options for operator based searching. The common operators are: OR, AND and NOT. this OR that this AND that this NOT that The OR operator is an open operator for example we could search for drone OR drones OR droning This will locate texts that contain any of these terms. If we wanted to restrict the search to those that contain all of the terms we would use AND. drone AND drones AND droning Note that this is a more restrictive form of search because the documents must contain all three words. In contrast, if we were interested in drone technology and not in other uses of the word drone such as in musical instruments we would use NOT. drone OR drones NOT droning This would only return documents where the search terms drone or droning appeared without the word droning. Another perhaps more precise strategy would be to also exclude music. drone OR drones NOT (bee OR bees OR “Apis mellifera” OR “honey” OR droning OR music) The parentheses in the above search query are important because they specify that documents containing either be or bees etc. should be excluded from the results. The use of NOT based searching is a powerful way of excluding irrelevant documents. Boolean operators are extremely important when constructing search terms and may be expressed in other ways if using databases programaticaly. For example in R both | and || mean OR and &amp; or &amp;&amp; means AND. In contrast Python uses logical OR, logical AND, logical NOT. A growing number of databases are powered by the Java based Apache Lucene or Solr. In Lucene and Solr in addition to the standard operators there is also “+” which specifies that a document must contain a term and may contain another term. +drone “unmanned aerial vehicle” To force both to appear we would use or the regular AND. +drone +“unmanned aerial vehicle” Note that the parentheses in the above version are important because it articulates that one or the other term should be excluded from the results. 2.2.3 Proximity Operators Proximity operators focus on the distance between words in a search term for example the operator NEAR with Web of Science allows the user to specify the distance between words such as (drone OR drone) NEAR/10 droning would find texts containing the word drone or drone within 10 words of the word droning. Another option, again from Web of Science is SAME. This is used in searches of the author affiliation field to treat two words as the same during search such as in the address field AD=(McGill Univ SAME Quebec SAME Canada). This search will treat the word Quebec and Canada as the same. Proximity operators can provide powerful tools for targeting a search of the scientific literature. However, when preparing to develop your search it is important to check the default settings used by the database and whether that meets your needs. In addition, it is important to note the operators that are available and the form that is expected. These will typically vary across the different databases. For example, many databases turn on stemming by default, use AND (rather than OR) as the default Boolean and may use ADJ (adjacent) as the default operator. Checking these settings at the beginning is important for avoiding confusing results when working across multiple data 2.2.4 Regular Expressions The use of regular expressions will be covered in greater detail in the discussion of text mining. However, it is worth noting that common regular expressions that you may be able to use in a literature databases include ^ starts with * any character wildcard. For example dron* would capture drone, drones, droned, droning etc. This can be used at the beginning, middle or the end of a term but is commonly used at the end. The wildcard should be used with caution. For example, a search for genomics related literature using the root genom and the wild card genom* will capture a potentially large number of results for the common German word genommen (took). $ ends with. For example drone$ would exclude drones and other close terms, however it would capture terms containing drone such as the italian word androne (meaning entrance or entrance hall). As such, beware of unexpected results. Regular expressions can be combined in a whole variety of ways. One of the most useful is exact matching. ^drone$ This will exactly match the word drone and no other term. Very basic engagement with regular expressions is a powerful tool and it is well worth learning the basics. A good place to start is the long standing Regular Expressions Tutorial. However, be warned that regular expressions can become complex and difficult to understand quite rapidly. A well known quote about regular expressions is attributed to former Netscape Engineer Jamie Zawinski in a Usenet discussion group from 1997. Some people, when confronted with a problem, think “I know, I’ll use regular expressions.” Now they have two problems.1 The point that is being made here is that regular expressions should not be the tool of first resort for every problem. Regular expressions can rapidly become very complex and difficult for a reader, including its author, to understand. Having said this a basic understanding of regular expressions is a very important part of the patent analysts toolbox as it allows you to precisely control what you are searching for and to parse the results. Tokenization of texts discussed above is an example of this that is typically based on word boundary matches (such as \\\\b) while named entity recognition in texts is often based on the identification of capitalized terms such as ^[[:upper]] or the equivalent ^[A-Z] to identify proper nouns (which are marked by the use of capital letters at the start of the word) such as people, place and other entity names. The precise form of a regular expression often depends on the language being used with Open Refine’s GREL or Google Regular Expression Language providing a nice practical introduction to using regular expressions as discussed in Chapter 8 of the WIPO Manual on Open Source Patent Analytics. Programming languages such as R include speciality packages such as stringr that make it easier to work with regular expressions and cheatsheets have been developed to assist in remembering regular expressions.2. Websites such as the Regular Expressions Tutorial and https://regex101.com/ allow you to test out regular expressions in a range of different programmming languages. 2.3 Precision vs. Recall At the end of the testing phase with scientific literature a set of new candidate terms and exclusion terms is the desirable outcome. For example, a more refined approach to the development of a search query for drone technology might look something like this. “drone” OR “drones” OR “UAV” OR “UAVs” OR “Unmanned Aerial Vehicle” OR “Unmanned Aerial Vehicles” OR “Pilotless Aircraft” NOT (“bee” OR “bees” OR “Apis mellifera” OR “honey” OR “droning” OR “music”) The use of the quotation marks in this case is intended to prevent the database from stemming the individual terms and the effect is to increase the level of precision in the inclusion and exclusion of terms. While it would be possible to modify this in a variety of ways using the wildcard or boundary markers, the importance of this type of approach is that it is simple, transparent, easy to reproduce and easy to modify in a way that can be tested. The discussion above is linked to a much larger body of literature on the distinction between Precision and Recall in information theory [refs]. For a literature database an example of this would be entering in a set of terms where the database returns 30 pages on drones that carry pizza boxes of which only 20 are relevant but fails to return the other 40 relevant documents. That is a precision rate of 20/30 = 2/3 as only 2 thirds of the returned documents are on topic. In contrast the recall rate is 20/60 or 1/3 because the database only returnd a third of the actual relevant documents.3 The first measure is about the accuracy of the results and the second is about the completeness of the results. In practice precision vs recall is aboout striking a good balance between accurracy (precision) and recall (completeness). One strategy for dealing with this is to start by favouring completeness by attempting to capture the universe of things relating to a topic and then filtering the data to arrive at more precise results to address the topic in question. In the next section we will use examples from the Scientific and Patent Landscape for Marine Genetic Resources that used exactly this strategy. The starting point for the research was to capture all scientific publications that contained an author from one of the ten South East Asian Countries or that contained a reference to the country in the title, abstract or author keywords of a publication. This approach captured the universe of things that needed to be captured. That universe proved to be 391,380 publications after filtering some of the larger country datasets on subject categories to reduce irrelevant subject areas. The aim here was to capture the universe of things that could potentially contain a marine species or genetic resouces. The second stage of this exercise involved text mining the titles, abstracts and author keywords for marine species names. This radically reduced the dataset to 6,659 scientific publications. As this makes clear, the use of this method can be costly in terms of the requirements of initial data retrieval but has the advantage of capturing the universe of relevant documents. On that basis the marine species in the data could be accurately targeted. One very significant constraint when working with the scientific literature as opposed to patent data is that it is very rare that the full text of a scientific article is available for search. This has a major but not readily quantifiable impact on recall because the major body of the text is o Debates around precision and recall and related concepts such as relevance are important across a wide range of computer and information retrieval fields including, for example, text and image classification in machine learning approaches discussed above. As regular users of search engines, patent analysts like other regular users will encounter the outcomes of decisions about how to handle the balance between precision and recall with varying degress of success in presenting useful results to the searcher. We will return to this topic in the discussion of machine learning. 2.4 Processing Scientific Literature Databases of the scientific literature commonly return a range of different fields when data is downloaded. These can vary widely but will commonly include most of the following: Author Name Author affiliation Title Abstract Author Keywords Document Identifier (e.g. doi, issn, isbn) Funding Acknowledgements (limited coverage) Cited references Citation counts Subject category (derived) Researcher identifier (ORCID, Researcher ID, PubMed Id, other ID) This data is mainly extracted from the front page of publication or, in the case of references, the end of the document. However the subject category is commonly added by the publication database itself and is commonly based on the classification of the subject area(s) of journals rather than individual articles. At the time of writing Web of Science used 252 Subject Categories and Scopus groups journals into 4 broad subject areas and 334 fields.4. A journal may be classified in more than one subject area with some such as Science, Nature and PLOS classified as interdisciplinary. The use of subject categories combined with citation analysis has been central to initiatives in the scientometrics community to develop maps of science (Leydesdorff and Rafols 2009, @Klavans_2009, @Rafols_2010 and for an alternative web click based approach see, @Bollen_2009) including online interactive maps such as the https://www.scimagojr.com/shapeofscience/ using Scopus data with a gallery of maps on the structure of science from a range of sources made available through the http://scimaps.org/. The processing of scientific literature follows a pattern that is very similar to patent data as discussed in Chapter 3. These steps can be described as follows: Deduplicate the records using document identifiers (such as Web of Science ISI Unique Identifier or equivalent) to ensure that no records is over counted. Review the dataset for noise and exclude noise as required. Clean author names Clean affiliation/organisation names Clean funding information to focus on funding organisations Visualise the data The deduplication of the data is important to avoid overcounting and can readily be achieved using document identifiers. Note that the best source for this is often the internal identifiers used by the databases as they are guaranteed to have 100% coverage unlike the doi field (normally confined to journal articles). The exclusion of noise from the dataset will commonly involve reviewing the data by subject category. Table 2.3 below displays the top subject categories in a sample of 1400 publications for the term drone or drones from Web of Science. Table 2.3: Top Web of Science Subject Categories for Drones Sample Data Records Subject Category keep review exclude 150 Entomology 0 0 1 136 Multidisciplinary Sciences 0 1 0 112 International Relations 1 0 0 100 Engineering, Electrical &amp; Electronic 1 0 0 82 Political Science 1 0 0 70 Law 1 0 0 64 Telecommunications 1 0 0 58 Ecology 0 1 0 52 Environmental Sciences 0 1 0 46 Zoology 0 0 1 43 Remote Sensing 1 0 0 40 Engineering, Aerospace 1 0 0 38 Robotics 1 0 0 37 Biology 0 1 0 36 Computer Science, Information Systems 1 0 0 Here we can see that we have a significant number of publcations in Entomology, and Zoology that are highly likely to be about bees rather than drone technology. When using VantagePoint it is easy to create groups such as keep, review and exclude that record decisions on data to include or exclude as a basis for refining a dataset. The review category is important because journal subject categories are somewhat crude. For example, Multidisciplinary sciences will include publications on drone technology and on bees. Agriculture related subjects are also a likely review category because bees and drone technology may appear in this category, for example for monitoring fields. The purpose of the review group is to allow time to view the records in particular categories with the aim of allocating all records to either keep or exclude at the end of this process. The use of subject categories is often a first place to look with either very high frequency or low frequency subject categories as good candidates for noise. However, a complementary second step is to look at the sources of the publications. A sample of this data for drone technology from Web of Science is presented in Table 2.4. Table 2.4: Top Web of Science Sources for Drones Sample Data Records Source Title keep review exclude 49 NEW SCIENTIST 0 1 0 40 APIDOLOGIE 0 0 1 26 PLOS ONE 0 1 0 23 JOURNAL OF APICULTURAL RESEARCH 0 0 1 20 SENSORS 1 0 0 18 AEROSPACE AMERICA 1 0 0 17 FOREIGN AFFAIRS 1 0 0 17 REMOTE SENSING 1 0 0 15 INTERNATIONAL AFFAIRS 1 0 0 14 IEEE SPECTRUM 1 0 0 13 JOURNAL OF APICULTURAL SCIENCE 0 0 1 12 ETHICS &amp; INTERNATIONAL AFFAIRS 1 0 0 12 JOURNAL OF INTELLIGENT &amp; ROBOTIC SYSTEMS 1 0 0 12 NEW YORK REVIEW OF BOOKS 1 0 0 11 INSECTES SOCIAUX 0 0 1 11 NATION 1 0 0 11 SCIENTIFIC REPORTS 0 1 0 10 CHEMICAL &amp; ENGINEERING NEWS 1 0 0 10 COMPUTER LAW &amp; SECURITY REVIEW 1 0 0 10 JOURNAL OF ECONOMIC ENTOMOLOGY 0 0 1 10 JOURNAL OF EXPERIMENTAL BIOLOGY 0 0 1 9 SCIENCE 0 1 0 9 SECURITY DIALOGUE 1 0 0 8 BULLETIN OF THE ATOMIC SCIENTISTS 1 0 0 8 INTERNATIONAL JOURNAL OF REMOTE SENSING 1 0 0 In this case we can see that publications such as Apidologie can readily be excluded where as journals such as PLOS ONE that publish across a range of fields would require review. We can also see that a number of social science and humanities subjects are entering into the picture and depending on our purpose we might want to focus publications down to those relating to remote sensing, engineering and related subjects. As part of this review process it is important not to second guess the technology area. For example, we should not assume that everything associated with biology should be excluded. Biomimicry is for example an important area of inspiration in some areas of drone technology (such as swarming behaviour) while some publications that refer to drones and biology refer to the use of drone technology in anti-poaching and conservation biology. It is precisely because of the lack of predictability of new and emerging areas of technology that an approach concentrating initially on recall and then on precision is often the most succesful route to accurate analytics. The alternative is for analyts to impose a definition of a new technology area on the field of research and thus potentially exclude important features of the technology field and debates around those fields (such as military drone strikes). The outcome of this review process is that each record falls into a keep or exclude category and a smaller dataset is generated containing the data the analyst wishes to keep. At this stage the main body of data cleaning focusing on author organisations (in the author affiliation) and author names along with the text in funding acknowledgements can begin. The basic procedure for name cleaning has been described in Chapter 8 of the WIPO Manual on Open Source Patent Analytics using the free Open Refine software tool. However, accuracy in name cleaning is best achieved using multiple match criteria to address cases where an author shares a name with another author but is a distinct person. VantagePoint provides a means to achieve this by linking a fuzzy logic name cleaning algorithm that clusters names based on similarity scores with a setting that allows another field to be used to match the data. That is a search for John Smith that is run without match criteria will group different John Smiths together. A clean up that is run by grouping John Smiths using the author affiliation will distinguish between John Smiths working at say the University of California or John Smiths working at London University. As this example also suggests name cleaning is often a multi-step process because in reality multiple John Smiths may work at the University of California. In that case a second step might be to use shared coauthors or subject categories as a basis for decision making using the keep, review, exclude method described above. The same approach is then applied to the applicant organisation where particular attention is required to organisations that share similar names but are distinct entities. Thus Washington University and the University of Washington are distinct entities. When cleaning organisation names note that decisions need to be made on how to address regional and international organisations and to provide notes in the resulting report or publication on decision-making to inform the reader. In considering the clean up process for author names described above not that it is often easier to begin by cleaning up the author affiliation names and then to clean author names using the cleaned organisation names as the match criteria. An important development in recent years has been the increasing use of author identifiers in publication records. A number of author identifier systems exist such as Researcher ID from Web of Science or Scopus ID and PubMed ID but the most important of these is ORCID which is a non-profit open access researcher identifier system. Where a researcher identifier is available these identifiers can be used to cluster variations of names with a degree of certainty that they are the same person or that persons with the same name with distinct ORCID IDs will in fact be distinct persons. At a higher level of detail ORCID ID public profiles can be looked up online to assist with assessing whether a researcher listed as belonging to one institution has moved to another. Cases of author movement will frequently involve a research working in the same area of research but listing more than one affiliation. ORCID identifiers help to resolve these cases. Funding data is a relatively new feature in publication databases and the presence of this data, which commonly appears in the Acknowledgements field can be spectacularly messy. For example: The COLOSS (Prevention of honey bee COlony LOSSes) network aims to explain and prevent massive honey bee colony losses. It was funded through the COST Action FA0803. COST (European Cooperation in Science and Technology) is a unique means for European researchers to jointly develop their own ideas and new initiatives across all scientific disciplines through trans-European networking of nationally funded research activities. Based on a pan-European intergovernmental framework for cooperation in science and technology, COST has contributed since its creation more than 40 years ago to closing the gap between science, policy makers and society throughout Europe and beyond. COST is supported by the EU Seventh Framework Programme for research, technological development and demonstration activities (Official Journal L 412, 30 December 2006). The European Science Foundation as implementing agent of COST provides the COST Office through an EC Grant Agreement. The Council of the European Union provides the COST Secretariat. The COLOSS network is now supported by the Ricola Foundation - Nature &amp; Culture. Literature databases are attempting to parse relevant information from this data such as the name of the funder and the contract or award number with varying degrees of success as follows: COST Action, FA0803 | EU Seventh Framework Programme, - | Ricola Foundation - Nature Culture, - In considering the discussion of regular expressions above note the focus in the parsing of this data on Nouns and Proper Nouns and numeric entries although it is likely that dictionary based approaches and machine learning based funding entity recognition are under development. An important challenge when dealing with funding information is determining whether data should be grouped or not. For example should funding from the European Commission under the Framework programmes and those under European regional or sectoral funds be grouped together. The answer to this question will depend in part on the level of detail required by the research. In general the approach taken, such as grouping all EU level funding together, should be made clear in an explanatory note to the reader when presenting the results of the data. One important observation on cleaning data is to consider how detailed the cleaning operation needs to be. For example, if only the top ten or top 20 results will be shown to the reader it is important to ensure that person, organisation or funding organisation have been cleaned to capture all relevant name variants to ensure the accuracy of counts. 2.5 Visualizing the Scientific Literature A wide range of options are available for visualising data from the scientific literature. Typically this will include basic data on trends, geographic distribution of records, subject areas, top ranking organisations and researchers. When working to visualize data it is a very good idea to become familiar with some of the excellent literature on this topic notably the classic book The Visual Display of Quantitative Information by Edward Tufte and Stephen Few (2012) Show Me the Numbers: Designing Tables and Graphs to Englighten. To illustrate some approaches to visualising data from the scientific literature we will use data from the WIPO report on marine genetic resources in South East Asian countries. 2.5.1 Dashboards Dashboards are a powerful and popular way of summarising data. Figure 2.1 shows a summary of the overall data on scientific research on marine genetic resources in South East Asia. Figure 2.1: Overview of Research on Marine Genetic Resources in ASEAN Countries Figure 2.2 displays details of the species, subject areas, organisations and authors. Figure 2.2: Overview of Marine Species, Organisations and Authors The effect of the use of dashboards is to convey the principle factual information in an easily digestible form. As readers will commonly scan from left to right, the first panel should contain the key information that you wish to convey. In the first case above the aim of the first panel is to draw attention to the fact that the data is from South East Asia. In the second panel the aim is to draw attention to the marine species as the key to interpreting what the data is about. Note that attention may be required to issues such as the size of fonts and the number of panels in communicating results to the reader. The visualisations above were created using Tableau and a practical guide to creating dashboards is provided in Chapter 9 of the WIPO Manual on Open Source Patent Analytics using the free Tableau Public software. One issue with visualisations of data in this way is that they are vertical. We do not see the relationships between entities in the data when in practice scientific research is commonly conducted as part of networks of collaboration on different levels. Network visualisations address this problem 2.5.2 Network Visualisation Figure 2.3 displays a network view of the relationships between authors involved in scientific research on marine genetic resources in South East Asia. The dots are sized based on the number of publications associated with an author. The lines or edges represent co-authored publications. The network has been limited to display authors with 20 or more publications. Figure 2.3: Research Networks for researchers with 20 or more publications on marine genetic resources These network images arfe important because they display relationships that are difficult to see in any other way. A particularly good example of this is networks of funding organisations as set out in Figure 2.4. Note that in Figure 2.4 the size of the dots represents the number of publications where the funding agency appears in the acknowledgements ad does not reflect the size of financial investments. The lines represent publications where different funding agencies appear in the acknowledgements. Figure 2.4: Network of Funding Organisations Supporting Research on Marine Genetic Resources The full extent of network relationships is typically invisible to network participants. This is particularly true for networks of funding organisations. However, network visualisation is a powerful tool for engagement with researchers and audiences interested in a particular subject. The network visualisations presented above were created using the free Gephi software and a practical guide to creating these networks is provided in Chapter 10 of the WIPO Manual on Open Source Patent Analytics. 2.5.3 Other forms of visualisation Data visualisation has advanced rapidly in recent years and the D3 Javascript library has been responsible for a virtual explosion in creativity with interactive graphics. Examples of visualisation possibilites can be viewed in the D3 gallery on Github https://github.com/d3/d3/wiki/Gallery. One among other possibly fruitful options for data visualization is the Sankey diagram a form of dendogram that aims to display the flow of energy between entities. Figure 2.5 displays the flow of research publications on a marine species in South East Asia into journals by subject area. Figure 2.5: A Sankey Diagram showing flows of research on marine genera into journals by subject areas This type of visualisation serves the useful purpose of showing the flow of research effort represented by publications as outputs into different subject areas. A particular strength of this visualisation is that we can see the proportion of research on a particular genus of marine organisms such as prawns in the genus Penaeus such as the Giant Tiger Prawn into journals on particular subjects. For Penaeus, a major focus of aquaculture in South East Asia, we can see that the flow of research energy is channeled towards fisheries, marine and freshwater biology and Veterinary Sciences (to address diseases with an effect on this commercially important genus such as viruses in the genus Vibrio). When viewed online this diagram is interactive and will highlight flows from a particular genus to a subject area. The ability to create Sankey diagrams depends in a large measure on a willingness to engage with a programming language such as Javascript, R or Python that provide libraries to make the calculations and generate the Javascript digrams. Thus the diagram above was generated with the D3network package in R. However, a number of online services offer the ability to create Sankey diagrams and these may meet your needs. 2.6 Linking the Scientific Literature with Patent Analysis Analysis of the scientific literature is important because it allows us to understand the landscape of research for a particular topic. In the case of drone technology we saw that exploratory searches could assist in identifying key words for the construction of more refined search strategies and to progressively exclude noise from the results. In the data we have presented above on research on marine genetic resources in South East Asia we processed the data to answer the following fundamental questions: Who (and with whom?) What Where When How These are standard questions in empirical research. The final question requires detailed attention to the literature itself in terms of understanding the precise subject matter of research by a particular individual or a research team. However, this type of landscape analysis allows us to investigate whether research has the potential to be transformed into a commercial product, method or process and therefore brings us to the patent and wider intellectual property system. This type of research can be useful on a range of different levels: universities may be interested in identifying research outputs that may have potential to turn into useful products, methods or processes companies active in particular sectors may be seeking to develop new products and are seeking to identify relevant existing research Funding agencies may be seeking to understand the existing outcomes of research investments and to identify relevant areas of priority research that promise to result in new and useful products. In many cases analysis of the scientific landscape will take place at a lower level than the ten countries covered by the research on South East Asian countries covered above. However, this example illustrates the possibility of using these methods and approaches to answer empirical questions at scale and then to drill down into the fine grained detail of research. One major question that arises here is how to link together research on the scientific literature with research in the patent system. There are two main answers to this. To use keywords and phrases identified in research from the scientific literature as the basis for searches of the patent literature. This is likely to be the most common approach. As discussed above access to sections of the literature such as titles, abstracts and author keywords allows for the application of basic text mining approaches to breaking texts into words and phrases. This in turn allows for the literature to be classified and refined to identify targets of interest. In software such as VantagePoint this is commonly done by sorting the data into groups. For example, in the case of drone technology one important area of research focuses on sensors while another separate area of research focuses on wireless devices to supply power to a drone while a third focuses on devices such as headsets and other devices for controlling a drone in flight. To focus on identifying individual researchers who are active in a research field who are also active in the patent system This approach to linking scientific research with patent data is rarer for the straightforward reason that it is much harder to do at scale than an approach using keywords. However, it has the advantage of providing a clearer view of researchers who are already active in commercial research and development with a high degree of precision. 2.6.1 Mapping Authors to Inventors The identifying researchers who are active in the patent system involves a three step process Joining a dataset with the scientific literature to a patent dataset and combining the inventor and author name fields. Identifying match criteria to establish whether an author and inventor are the same person Applying the match criteria to arrive at a dataset that includes authors who are also inventors Reviewing and summarising the data. The first step in the process involves identifying the appropriate approach to creating a patent dataset. This could involve the use of a broad set of terms to capture the likely universe of patent activity using the scientific literature as a guide to term selection. For example, in the case of drone technology it would be logical to create a working dataset using terms discussed above such as drone and unmanned aerial vehicle. The primary issue here is spreading the net wide enough to capture the universe of activity while narrowing the data sufficiently to avoid using a vast dataset. For research on national level activity, such as in the case of the landscape for research on marine genetic resources in South East Asia the approach taken was to identify patent activity from the national collections and patent activity worldwide linked to a South East Asian inventor or applicant followed by text mining the data for marine species and treating that data as the working dataset. This approach required access to patent data at scale and the ability to process that data (performed in VantagePoint and R). VantagePoint is an important tool for joining datasets of different types and creating a common field. Thus, in the research on South East Asia the scientific data and patent data were combined into one dataset . In the next step the authors full name field and the inventor name field were combined together. In both cases the names had previously been cleaned. In the case of the scientific literature there were a total of 17,625 names and in the case of the patent data there were 9,832 names. The next step in the approach is the use of match criteria. In this case the following criteria were used. An author and a co-author appeared as inventors in the same patent document The name of an author and the organisation listed as the applicant matched with the author affiliation. An author name matched with an inventor name and the marine species name appeared in both the scientific publication and a patent document The purpose of these criteria is to identify author-inventors and it is important to note that the third match criteria can vary from dataset to dataset. The important point is to identify and use match criteria. In order to qualify as an author inventor the record was required to meet at least one and preferably two of the criteria above. Experience has revealed that the names of co-authors who appear as inventors is the most accurate match criteria. One exception to this is East Asian names where, in accordance with traditional naming practices, the names of co-authors and inventors may be very common. This can result in false positive matches and it is therefore important to isolate such cases to test against the other match criteria. As discussed above, one useful method for working with large amounts of data is to allocate records to keep, review and exclude groups and adopt a method of multiple passes. At the end of the first pass the review group will typically be large because it marks up those cases where there was an element of uncertainty on the match criteria. For example, where the author and co author names appear to match with inventors but are very common names. Alternatively, the first criteria might have been met but the affiliation and organisation records did not match. Finally, for review include instances where there is an author to inventor match but only the species names are shared. During the second and potentially multiple other passes, the review group is progressively allocated to either keep or exclude. While the same method can be used with programming languages VantagePoint is designed to facilitate this type of close work and has the advantage that other data fields can be reviewed for matching as the cleaning process proceeds. At the end of the process a total of 290 authors of research on marine genetic resources in South East Asia who are also inventors were identified. As this suggests, developing this type of analysis involves reviewing a large number of records with the expectation of a low number of results. A particular advantage of the use of match criteria is that it limits the high probility of false positive matches if match criteria are not used. As this also suggests mapping researchers from the scientific literature into the patent literature can be very time consuming. This is a particular problem when research is on a large scale such as the level of millions of records. The problem of name disambiguation and corresponding challenges with name cleaning have proved to be a persistent challenge in both the scientific literature and in the patent literature. However, there are signs that the situation may be at least improving even if it is not solved. In the case of the scientific literature the growing us of free ORCID identifiers promises to help improve but not solve the challenge of name disambiguation. At the time of writing over 5 million ORCID identifiers have been issued and an increasing number of funding organisations and publishers are either requiring or requesting an ORCID identifier. Clarivate Analytics has also made the relationship between its longstanding Researcher ID system and ORCID seamless. In an innovative move the Lens Patent Database now encourages researcher-inventors to associate their ORCID. In addition, the Lens has linked over 10 million non-patent literature citations to ORCID records so that researchers can see patent literature that cites their research. This suggests that ORCID identifiers may potentially have an important role to play in name disambiguation across the scientific and patent literature if uptake by researchers continues to increase rapidly. In a separate development in 2015 the USPTO hosted an Inventor Disambiguation Workshop to discuss the problem of inventor name disambiguation.5 As a result of a competition held by the USPTO a team from the University of Massachusetts Amherst led by Andrew McCallum and Nicholas Monath developed an algorithm using discriminative hierarchical coreference or in essence a decision tree model for clustering inventor names based on coreferences to other data fields in the record (for a detailed description of the approach see Wick, Singh, and McCallum 2012). The outcome of this research was applied both the the USPTO inventor and assignee field and the creation of new tables with links to the original raw tables. While it is not expected to be error free the PatentsView data tables may offer opportunities to more easily establish linkages between data from the scientific literature and patent data, at least for USPTO data because it is freely available and has been pre-processed. The ability to match names between the scientific literature and patent literature at scale remains as a significant and time consuming challenge. However, in the case of ASEAN countries it revealed author-inventors such as Baldomera Olivera from the Philippines who pioneered research on cone snail toxins that would feature on the front page of Science magazine and lead to an approved pharmaceutical. Other researchers identified through this approach included husband and wife team Hu Bow and Ding Jeak Ling from the National University of Singapore who identified a recombinant cDNA factor from the Horseshoe Crab that is now used in endotoxin assays and biosensors. In short, the approach yields detailed evidence of researchers who have succesfully licensed inventions that have become products on the market. In practice, the majority of research activity does not result in patent activity. However, combining analysis of the scientific literature with the patent literature can lead to the identification of potential candidates to be taken forward for development and examples of successful licensing of research and inventions that can serve as positive examples for researchers and policy makers elsewhere. We will close this discussion of methods and approaches for linking analysis of scientific and patent literature with a recent development to link literature citations and patent data. 2.7 Linking Citations with Patent Literature An alternative way to think about the relationship between the scientific literature and patent activity is to focus on non-patent literature citations (Callaert et al. 2006). In a recent development the open access Lens patent database has done extensive work to link document identifiers in the non-patent literature to the Crossref database of metadata on over 96 million publications and to link records with PubMed and Microsoft Academic. The effect is to create a bridge based on identifiers between the scientific and the patent literature. Figure 2.6 Figure 2.6: Literature Citations Linking to Patent Citations and to external data sources in the Lens This figure shows the top ranking literature citation across the data for the well known Basic Local Alignment Search Tool or BLAST that is widely used in fields such as genomics. Each entry links to a summary table include Medical Subject Headings (MeSH) terms where appropriate and a Citations page that will reveal Patent citations and Literature citations. Registered users, registration is free, can store and then export the results. Table 2.5 presents a sample of fields from the top 5 of the 9000 exported results from a search of Lens Scholar for “synthetic biology”. Table 2.5: Lens Scholar Exported Results for Synthetic Biology Title Referenced by Patent Count Publication Year Citation IDs Author/s Accurate multiplex gene synthesis from programmable DNA microchips. 188 2004 (magid) mag2027912527; (doi) 10.1038/nature03151; (pmid) 15616567 Jingdong Tian; Hui Gong; Nijing Sheng; Xiaochuan Zhou; Erdogan Gulari; Xiaolian Gao; George M. Church De novo biosynthetic pathways: rational design of microbial chemical factories. 91 2008 (pmid) 18725289; (magid) mag2092471565; (doi) 10.1016/j.copbio.2008.07.009 Kristala L. J. Prather; Collin H. Martin Harnessing homologous recombination in vitro to generate recombinant DNA via SLIC. 81 2007 (doi) 10.1038/nmeth1010; (pmid) 17293868; (magid) mag2102440675 Mamie Z. Li; Stephen J. Elledge Microfluidic PicoArray synthesis of oligodeoxynucleotides and simultaneous assembling of multiple DNA sequences 65 2004 (pmcid) pmc524290; (pmid) 15477391; (magid) mag2146545072; (doi) 10.1093/nar/gkh879 Xiaochuan Zhou; Shi-Ying Cai; Ailing Hong; Qimin You; Peilin Yu; Nijing Sheng; Onnop Srivannavit; Seema Muranjan; Jean Marie Rouillard; Yongmei Xia; Xiaolin Zhang; Qin Xiang; Renuka Ganesh; Qi Zhu; Anna Matejko; Erdogan Gulari; Xiaolian Gao Gene Designer: a synthetic biology tool for constructing artificial DNA segments 59 2006 (pmcid) pmc1523223; (pmid) 16756672; (magid) mag1760665500; (doi) 10.1186/1471-2105-7-285 Alan Villalobos; Jon E. Ness; Claes Gustafsson; Jeremy Minshull; Sridhar Govindarajan As this suggests, growing trends towards the federation of the scientific and patent literature present important opportunities for designing search strategies and more flexible approaches to the analysis and communication of results building on both the scientific and the patent literature. 2.8 Conclusion This chapter has focus on methods for working with data from the scientific literature, using analysis of the scientific literature to build up a search strategy, the development of a scientific landscape study and methods for linking scientific literature to patent analytics. References "],
["patents.html", "Chapter 3 Counting Patent Data 3.1 The structure of patent numbers 3.2 Preparing to Count Patent Data 3.3 Counting Priority or First Filings 3.4 Counting Priority Applications 3.5 Counting Applications 3.6 Trends by Country using Publication Data 3.7 Patent Families 3.8 Forecasting Patent Activity", " Chapter 3 Counting Patent Data This chapter provides an in depth introduction to the development of descriptive patent statistics. While many readers will be familiar with patent statistics and the OECD Patents Statistics Manual is an important resource for thinking about patent statistics, to date a step by step approach to creating patent counts using real world data has been lacking (OECD Patent Statistics Manual 2009). This chapter aims to fill this gap by working up from the analysis of the structure of patent numbers through to the creation of counts priority or first filings. This is followed by exploration of patent families and concludes by graphing patent trends. The Chapter makes extensive use of the drones patent dataset and instructions on how to install it are provided the How to Use the Handbook section at the front of the book. 3.1 The structure of patent numbers Patent numbers are the key identifiers for patent documents. At the time of writing there are presently 107 million patent and related documents within the European Patent Office central DOCDB. The key to working with and counting these documents is an understanding of the structure of patent numbers. Table 3.1 presents the principle formats of patent numbers as they are commonly retrieved from patent databases. Table 3.1: Examples of Types of Patent Numbers priority_number application_number publication_number US2016578323F 2016-09-20 US2016578323F 2016-09-20 USD801224S1 US15360203A 2016-11-23 US15360203A 2016-11-23 US9807726B1 US62133061P 2015-03-13 US15069675A 2016-03-14 US9804596B1 US14622134A 2015-02-13 US14622134A 2015-02-13 US9802728B1 JP2015122335A 2015-06-17; WO2016JP67809A 2016-06-15 US15322008A 2016-12-23 US9802691B2 US15346251A 2016-11-08 US15346251A 2016-11-08 US9805273B1 For each of these numbers we observe the following structure A two letter country code such as US (United States) or KR (South Korea) A numeric identifier that, for more recent years, may include the year e.g 2016578323 or 15263985 A letter or combination of a letter and a number such as A, A1, B1, B2, S or P denoting the Kind of document The date in Year - Month - Day format (known as YYYY-MM-DD) It is important to note that the patent numbers that are retrieved from patent databases are not necessarily presented in the way they are stored. For example, the country code, the numeric identifier, the kind code and the date are often stored in separate columns and are then combined together. When working with different databases this can be reflected in spaces between the country code, the number and the kind code. In addition, the original entries on patent application forms often include forward slashes /. In some cases databases will present numbers containing the forward slash character and in others they will be deleted as the do not add to the distinctiveness of the identifier. Be aware that some patent databases, notable Derwent Innovation from Clarivate Analytics, add padding 000s in the middle of some patent numbers to make them uniform and may add the year field at the beginning of patent numbers. For this reason using patent numbers across different databases is not as straightforward as it might be. Slight variations in the format will be the most common reason that a patent number is found in one database but not in another. 3.1.1 The country code The two letter country code denotes either the country of filing, the country of application or the publication country. For example, in Table 3.1 above, KR201528901A was first filed as an application in South Korea and then in the United States (US15057264A) and then published as a patent grant (US9807364B2) in the United States. A full list of two letter country codes, including the codes for the Patent Cooperation Treaty (WO) and regional instruments is available in the WIPO Handbook on Industrial Property Information and Documentation under standard ST.3 Recommended Standard on two-letter Codes for the Representation of States, Other Entities and Intergovernmental Organizations. The same table is also available on Wikipedia. Software tools such as VantagePoint provide thesaurii that will convert country codes to country names. The country codes tell us where a document is filed and published. This provides the foundation for identifying trends by country using a range of different counts and for geographic mapping. 3.1.2 The numeric identifier The second element of a patent number is a numeric identifier. As noted above, it is important to note that these identifiers may be edited by databases. For example, the Derwent World Patent Index often uses either a single or padding zero between the year in a field and the number. This probably arose from an effort to make patent numbers a uniform length but has the effect that these documents cannot easily be retrieved from databases that do not use padding zeros (such as esp@cenet). In other cases the numbers may include characters such as “/” that are not formally speaking part of the identifier. The kind code may also be added in some databases but not in others. 3.1.3 Kind Codes Kind Codes appear as letter and number combinations after the numeric identifier. Kind codes describe the type of document and the publication level. Kind codes are documented in WIPO Standard ST.16 Recommended Standard Code for the Identification of Different Kinds of Patent Documents. Formally speaking Kind Codes are applied to: “patents for invention, inventors’ certificates, medicament patents, plant patents, design patents, utility certificates, utility models, patents or certificates of addition, utility certificates of addition, and published applications therefor” (WIPO ST.16 page 3.16.1, October 2016) In connection with the publication level, the definition explains that: “a “publication level” is defined as the level corresponding to a procedural stage at which normally a document is published under a given national industrial property law or under a regional or international industrial property convention or treaty&quot; So, to take a common example, a patent document may be published at the application stage. This is commonly the first procedural stage and is the first publication level. In many countries standard patent applications will receive the kind code A at this first publication level. In many countries, when a patent is granted the document enters the second publication level and it is published with kind code B. Other types of patent documents commonly receive their own kind codes denoting their type. For example Utility Models receive the kind code U while design patents received kind code S. Kind codes are often accompanied by a number that adds additional information about the type of document. Within the WIPO standard these numbers range from 1 to 7 with numbers 8 and 9 reserved for corrections to the bibliographic data (e.g. A8) or to any part of the document (e.g. A9). WIPO Examples and Kinds of Patent Documents forms part of the WIPO Handbook on Industrial Property Information and Documentation setting out common Kind Codes and is recommended reading for patent analysts. Quick reference tables are also produced by Clarivate Analytics and national patent offices and are available online. The use of patent kind codes has evolved over time and this can make accurate interpretation of a kind code difficult. In practice: The use of a kind code may vary in the same country over time. For example in the United States prior to 2001 patents were only published when they were granted (first publication level) and they were awarded kind code A. From 2001 onwards the United States adopted common practice elsewhere and published applications which now receive kind code A (as the first publication level) while patent grants are now the second publication level (and receive kind code B); The use of kind codes varies between countries. As a very rough rule of thumb, publications with kind code A commonly mean the publication of an application. Publications with kind code B mean publication of a patent grant. But, this is not always true and it can only be described as a rough rule of thumb. This rule can normally be used when working with data from the main jurisdictions such as the United States (bearing in mind the pre and post 2001 changes considered below), the European Patent Office and the Patent Cooperation Treaty (which only covers first level publications or applications) and Japan. However, when working with country level data to elaborate trends for applications and grants it is important to review the use of kind codes in each country to be covered and to identify changes in the use of kind codes over time. When developing data on statistical trends for applications and grants a note should normally be added to inform readers that the data is approximate in cases where the use of kind codes has not been thoroughly explored and documented. Patent kind codes denoting publication level and the kind of document (e.g. U) are important for statistical purposes because they allows for the identification of duplicates and, depending on the purpose of the analysis, the removal of unwanted data types (such as Utility models, design patents and plant patents) or the isolation of specific types of document. For most purposes kind codes are important for identifying patent applications and grants and critically for identifying republications of the same document (duplicates) The most common kind codes encountered in patent data are: First publication level (commonly but not exclusively patent applications) A1 A2 A3 Second publication level (commonly but not exclusively patent grants) B1 B2 B3 This means, to take a fictional example from the USPTO and its common kind codes, that: US1234A1 Patent Application Publication US1234A2 Patent Application Publication (Republication) US1234A9 Patent Application Publication (Corrected Publication) US1234B1 Granted Patent (no previously published as a patent application) US1234B2 Granted Patent (previously published as a patent application) In this example we have 3 potential publications of the same application and one publication of a patent grant (although corrections to a granted patent are possible). For the purpose of counting patent data how we deal with these republications or duplicates depends on the question we are trying to answer. If we wanted to identify the priority application that is closest to the investment in research and development we would choose the earliest application number available to us (that may or may not have been published). In other cases we may want to count all applications that stem from a first filing or set of filings while in others we may want to identify applications and grants but remove administrative republications (simple republications and corrections or publication of the international search report) from the counts. The main issue that arises here is determining what we wish to include and exclude from counts. One general approach to this issue is to simply remove all republications of the same document (count the document only once on the earliest in the series) . For example, if we were interested in counting patent applications and patent grants in the United States we would count US1234A1 and we would count the patent grant (US1234B2) and exclude the republications of the application. If we are only interested in counting patent applications we might simply remove the kind code denoting the different publication levels to count document US1234 only one. In practice, basic patent statistics commonly involves the use of multiple counting methods as we will see in more detail below. As the discussion above makes clear when working with patent data to elaborate patent counts we must address multiplier effects. These take two main forms: Republication of the same basic document in the same jurisdiction as applications, grants, or with modifications as continuations, continuations in part or divisionals. Submission of applications under regional patent instruments or the Patent Cooperation Treaty (WO) and their republication as applications, grants, other administrative publications or divisionals (in relevant jurisdictions). Thus, under the Patent Cooperation Treaty an applicant may submit the same patent application for consideration in up to 152 Contracting States. In practice this is rare but in theory a single application could potentially lead to the republication of the same document as an application and grant 304 times (assuming a single publication of an application and the publication of a grant in each country). While this would be a very unusual case, it reveals the potential multiplier effects in patent counts introduced by regional instruments such as the European Patent Convention and the Patent Cooperation Treaty. As we will see below, in some cases a single document may be linked to over 1000 publications. 3.2 Preparing to Count Patent Data The patent identifiers discussed above provide the key for tracking patent documents around the world, using the concept of patent families discussed below, and for elaborating patent counts. The most important single piece of information when thinking about patent counts using identifiers is that patent patent data involves multiplier effects that leads often leads to the duplication or republication of the same document or a document that has been modified based on an earlier version. Patent identifiers provide the basis for navigating these multiplier effects and the basis of patent counts commonly consists of removing duplicates or deduplication at different levels or combining documents in a variety of ways. We will use the drones dataset as an example of this. Table 3.2 shows a sample of different patent numbers. Table 3.2: Priority, Applications, Publication and INPADOC Family Members priority_number application_number publication_number inpadoc_family_members US2016578323F 2016-09-20 US2016578323F 2016-09-20 USD801224S1 NA US15360203A 2016-11-23 US15360203A 2016-11-23 US9807726B1 NA US62133061P 2015-03-13 US15069675A 2016-03-14 US9804596B1 NA US14622134A 2015-02-13 US14622134A 2015-02-13 US9802728B1 NA JP2015122335A 2015-06-17; WO2016JP67809A 2016-06-15 US15322008A 2016-12-23 US9802691B2 NA We can see here that one or more priority numbers are linked to application numbers. In some cases those numbers are identical while in other cases they will be distinct. The application number is linked to one or more publication numbers. Patent databases commonly return data based on publication numbers. However, this is often only a partial picture of the set of documents linked to an application or set of applications and their underlying priority filings. In the fifth example in Table 3.2 we can see that we have one publication number. However, we can see that under the INPADOC Family Member Number there are multiple patent publications that are not captured in the publication number field. There are two reasons for this. A search of a patent database commonly returns patent publications based on criteria such as limiting the search by jurisdiction. This does not reveal all documents linked to a filing or set of filings worldwide. The INPADOC Family Members column groups publications based on a particular definition of a patent family. The number of documents will vary here depending on the definition of the patent family used in the data and whether the documents are deduplicated. Table 3.3 summarises the data by showing the counts of the different types of documents. Table 3.3: Sample of Patent Counts linked to the earliest priority number earliest_priority priority_count application_count family_count US2016620248F 2016-09-02 1 1 1 US14835329A 2015-08-25 1 1 2 US15174819A 2016-06-06 1 1 1 US2013898275P 2013-10-31 2 1 1 US2015274112P 2015-12-31 8 18 28 US201476360P 2014-11-06 7 4 7 Table 3.3 helps to make clear that we may be dealing with simple cases (one priority or first filing) leads to one application and one family member. Or, we may be dealing with a group of priorities leading to multiple applications and multiple family members. This helps to clarify that, when working with patent data we are often dealing with many to many relationships In the next section we will progressively move up from counting patent documents using priority numbers and finish by using counts of INPADOC family members to elucidate trends for drone related technology. 3.3 Counting Priority or First Filings When a patent application is filed for the first time anywhere in the world it becomes the priority document or first filing. The use of this term is based on the 1883 Paris Convention. The WIPO summary of the key provisions of the Paris Convention explains the right of priority introduced by the Convention as follows. The Convention provides for the right of priority in the case of patents (and utility models where they exist), marks and industrial designs. This right means that, on the basis of a regular first application filed in one of the Contracting States, the applicant may, within a certain period of time (12 months for patents and utility models; 6 months for industrial designs and marks), apply for protection in any of the other Contracting States. These subsequent applications will be regarded as if they had been filed on the same day as the first application. In other words, they will have priority (hence the expression “right of priority”) over applications filed by others during the said period of time for the same invention, utility model, mark or industrial design. Moreover, these subsequent applications, being based on the first application, will not be affected by any event that takes place in the interval, such as the publication of an invention or the sale of articles bearing a mark or incorporating an industrial design. One of the great practical advantages of this provision is that applicants seeking protection in several countries are not required to present all of their applications at the same time but have 6 or 12 months to decide in which countries they wish to seek protection, and to organize with due care the steps necessary for securing protection.6 The OECD Manual on Patent Statistics describes the priority number and the priority date as follows Priority number. This is the application or publication number of the priority application, if applicable. It makes it possible to identify the priority country, reconstruct patent families, etc. Priority date. This is the first date of filing of a patent application, anywhere in the world (usually in the applicant’s domestic patent office), to protect an invention. It is the closest to the date of invention. (OECD 2009: 25) The most important issue here from the perspective of patent counts is the priority date. Table 3.3 above revealed that patent applications may be linked to multiple underlying priority applications. The earliest filing, as shown in Table 3.3, is the Paris priority in the sense that it is the first of a set of filings giving rise to a claimed invention. In the simple cases as shown in the first, second and fourth entries of Table 3.2, the priority number and the application number are the same. Therefore we have identified the priority or first filing. However, there are two other cases in Table 3.2. The fifth example shown in Table 3.4 reveals a common case where a national level filing gives rise to an international filing under the Patent Cooperation Treaty. 1. National Filing to International Filing First let’s look at the example in Table 3.2 Table 3.4: Priority, Applications, Publication and INPADOC Family Members priority_number application_number publication_number inpadoc_family_members US2016578323F 2016-09-20 US2016578323F 2016-09-20 USD801224S1 NA US15360203A 2016-11-23 US15360203A 2016-11-23 US9807726B1 NA US62133061P 2015-03-13 US15069675A 2016-03-14 US9804596B1 NA US14622134A 2015-02-13 US14622134A 2015-02-13 US9802728B1 NA JP2015122335A 2015-06-17; WO2016JP67809A 2016-06-15 US15322008A 2016-12-23 US9802691B2 NA JP2015122335A 2015-06-17 is for a Floating Type Flying Body. We can see in row 5 that JP2015122335A 2015-06-17 lists a second priority number for a Patent Cooperation Treaty filing WO2016JP67809A 2016-06-15 . At first sight this leads to US patent application US15322008A 2016-12-23 that is published as US9802691B2. However, when working with priority numbers we commonly encounter multiple applications arising from the priorities. Table 3.5 displays counts of the priorities and applications linked to JP2015122335A 2015-06-17 for a Buoyant Aerial Vehicle Table 3.5: Applications arising from JP2015122335A 2015-06-17 earliest_priority priority_count application_count JP2015122335A 2015-06-17 2 4 The second priority number is the Patent Cooperation Treaty WO2016JP67809A 2016-06-15. Table 3.6 shows the sequence of applications arising from the the two priorities and the INPADOC patent family. Table 3.6: Patent Applications arising from JP2015122335A with PCT application WO2016JP67809A priority_number application_number publication_number inpadoc_family_members JP2015122335A 2015-06-17 US15322008A 2016-12-23 US9802691B2 NA JP2015122335A 2015-06-17 EP2016811654A 2016-06-15 EP3150483A1 EP3150483A1 20170405; EP3150483A4 20170920; JP05875093B1 20160302; JP2017007411A 20170112; US20170137104A1 20170518; WO2016204180A1 20161222 JP2015122335A 2015-06-17 WO2016JP67809A 2016-06-15 WO2016204180A1 EP3150483A1 20170405; EP3150483A4 20170920; JP05875093B1 20160302; JP2017007411A 20170112; US20170137104A1 20170518; WO2016204180A1 20161222 JP2015122335A 2015-06-17 JP2015122335A 2015-06-17 JP05875093B1 EP3150483A1 20170405; EP3150483A4 20170920; JP05875093B1 20160302; JP2017007411A 20170112; US20170137104A1 20170518; WO2016204180A1 20161222 The first point to note is that Japanese priority application JP2015122335A 2015-06-17 becomes application JP2015122335A 2015-06-17 and is then published as a patent application in Japan as JP2017007411A 20170112 in January 2017 (first publication level) and also as a granted patent JP05875093B1 20160302.7 However, the Patent Cooperation Treaty application WO2016JP67809A 2016-06-15 filed a year later triggers applications (on the same date) in the United States and at the European Patent Office. Application number US15322008A 2016-12-23 is published in May 2017 as US20170137104A1 20170518 (first publication level) and on the second publication level as US9802691B2. European application EP2016811654A 2016-06-15 is published as EP3150483A1 20170405 (first publication level with the search report) and as EP3150483A4 20170920 with a supplementary search report. Note here that the database entry for the inpadoc family members for the United States application is blank (NA stands for Not Available) indicating that this record had not been updated or correctly updated. An up to date view of the patent family is available from esp@cenet and includes the US records and more recent patent activity. The priority data in this case reflects the decision taken by the applicant on the filing route to pursue protection in other countries in this case the United States using the Patent Cooperation Treaty. The Patent Cooperation Treaty has the advantage of extending the time that applicants enjoy before deciding where else to pursue protection from 12 months under the Paris Convention to up to 30 months [CROSS CHECK AND REF]. Applicants also enjoy reduced costs compared with the Paris Convention because a single application is submitted that may then go forward for consideration in other Contracting States. Note that the filing route can be detected in the priority number WO2016JP67809A 2016-06-15 which contains the country code JP as part of the application number. It is commonly the case that the listing of priorities numbers follows a sequence where the first priority number listed on a document is the earliest, followed by later applications.8 As this example makes clear when working with patent data we are typically following a pattern consisting of: priority number (earliest) &gt; application number &gt; publications (under different family definitions) At each step the publications associated with the original filings multiply. In this case we are observing the distinctive filing route arising from a single priority filing. The filing route has nothing to do with the invention per se. However a more complex example reveals that inventions may arise from multiple claimed inventions. 2. Multiple Inventions We have seen above that in some cases patent applications involve multiple priority numbers. Most will follow the pattern identified above. However, in some technology areas, notably those involving computing, multiple priority numbers may be quite common. In the case of the drones dataset a single application US14815121A 2015-07-31 lists no less that 146 priorities and has given rise, at the time of writing, to an INPADOC patent family consisting of 340 publications. This example concerns a Wireless Power System for an Electronic Display with Associated Impedence Matching Network. It can be identified in esp@cenet using publication number US2015357831A1 and a summary is presented in Table 3.7. Table 3.7: Multiple Priorities and US Provisional and Continuation Filings priority_country n AU 1 TW 1 US 144 Table 3.7 reveals that the majority of priorities are domestic US priorities (144) with two foreign priorities in the form of Australia (1) and Taiwan. The earliest priority filing listed in the set of priorities is US2007647705A 2007-12-28 and the latest are in 2017 signifying that the underlying filings linked to this application spanned nearly a decade. Of the 143 priorities linked to the application originating from the United States 107 carry kind code A and 36 contain kind code P for a Provisional application. This therefore appears to be a case dominated by so called continuation and continuation in part, divisional and provisional applications. In the United States applicants are allowed to file continuation and continuation in part applications. In the case of continuations the applicant adds new claims that claim priority to the earlier filed application. In the case of continuation in part, these applications add new subject matter focusing on enhancements to the original application. Divisional applications claim priority to the original application but claim distinct new inventions rather than adding new claims or subject matter. In the United States and elsewhere divisional applications often arise where the examiner determines that an application contains more than one invention. Provisional applications are a distinct category whereby an applicant for patent rights in the United States may submit and claim priority to what is effectively an outline of a full application that does not contain patent claims. These applications are useful for establishing priority but do not take effect until an actual application is filed and they are not published. Details of the procedures for these types of patent applications are found in the USPTO “Manual of Patent Examining Procedure (MPEP)”. The use of continuation and continuation in part applications in the United States has been a significant focus of debate and criticism (Hegde, Mowery, and Graham 2007). As Dechezlepretre et. al. have recently highlighted: “At the national or regional levels, applicants can in turn use second domestic filings, including divisional and continuing applications, to delay a patent grant. By filing a di- visional application while the parent application is still pending, applicants can obtain a second (or possibly more) divisional patent(s) granted later, and meanwhile maintain some uncertainty on the claims. In the U.S. patent system, continuations and continuations-in- part can be filed after the examination, and aim precisely at adding more claims to a patent (Hegde et al. 2009). Filing a first application with narrow claims thus makes it possible for the applicant to obtain several patents on the same invention, thereby gradually extending the overall scope of the claims and even, in the case of continuations-in-part, the duration of the patent family.” (Dechezleprêtre, Ménière, and Mohnen 2017, at 802) From the perspective of patent counts the question that arises here is what should be counted? Having gained an understanding of some of the potential issues involved in preparing to count patent data we now turn to methods for counting priority applications 3.4 Counting Priority Applications Counts of priority filings are widely used in patent statistics and economic analysis because they focus attention on the relationship between the filing of an application for an invention and the underlying investment in Research and Development leading to the invention. Viewed from this perspective, and as highlighted in the OECD Patent Statistics Manual, the earliest filing of a patent application provides a proxy indicator for investments in Research and Development in a particular technology area. This information can therefore be used as a basis for identifying and exploring trends. Within the economics literature the preference therefore is for identifying and counting the earliest priority filing in a set of priorities. This is the approach that we will adopt here. However, the discussion of the Witricity case above involving multiple filings also reveals that we should be aware of some of the potential limitations of that approach. Thus, as mentioned above the priority filing of a patent application normally corresponds with the identical application number in the priority field. However, in the Witricity case the earliest filing was listed in December 2007 while the application was in mid 2015 roughly 7 years after the original filing. This raises the question of whether the date corresponding with the specific claimed invention should be taken or whether the earliest date should be taken as the basis for the proxy indicator. In practice, in methodological terms it is easiest to identify the earliest priority in a set as the basis for elucidating trends in priority filings. However, this type of issue helps to illustrate that counts of priority filings are a proxy for underlying investments in Research and Development or in formal terms an output indicator and depending on your needs may merit refinement to more closely match the required granularity. Counting patent filings by priority involves x basic steps Checking the priority field for missing priority data (we can’t count missing data) Separating out the concatenated column containing priority numbers. These numbers are commonly separated with a semi-colon. Removing extra white space that is revealed by the separation process Separating out the priority number and the priority date (commonly using the space between these fields) Grouping the priority numbers by the application number and rank them from 1 to x with 1 being the earliest Filter the priority numbers to the earliest (rank 1) Detect duplicate priority numbers arising from those that share application numbers in the source set and remove them Graph the results The methodological steps required for this task can be performed using tools such as Open Refine which can easily separate out the data or in VantagePoint. The key challenge is in grouping and ranking the priority numbers by the earliest data. This is most easily achieved using a programming language (such as an SQL GROUP BY, PARTITION BY and RANK) or in a language such as Python or R. In the case of R this can be achieved in the following lines of code. The code is commented to show the steps identified above. earliest_priority &lt;- numbers %&gt;% select(priority_number, application_number) %&gt;% drop_na(priority_number) %&gt;% # drop empty priority fields separate_rows(priority_number, sep = &quot;;&quot;) %&gt;% # separate priority numbers on &quot;;&quot; mutate(priority_number = str_trim(priority_number, side = &quot;both&quot;)) %&gt;% # trim whitespace separate(priority_number, into = c(&quot;priority&quot;, &quot;priority_date&quot;), sep = &quot; &quot;, remove = FALSE) %&gt;% # extract the date mutate(priority_date = lubridate::ymd(priority_date)) %&gt;% mutate(year = lubridate::year(priority_date)) %&gt;% # add the priority year field mutate(priority_number = str_trim(priority_number, side = &quot;both&quot;)) %&gt;% # trim whitespace mutate(priority_country = str_sub(.$priority_number, 1,2)) %&gt;% # extract the priority country group_by(application_number) %&gt;% # group by application number mutate(filing_order = rank(priority_date, ties.method = &quot;first&quot;)) %&gt;% # rank by priority date ungroup() %&gt;% # remove grouping for later calculations filter(filing_order == 1) %&gt;% # filter to the earliest priority at rank 1 mutate(duplicate_priority = duplicated(.$priority_number)) %&gt;% # identify duplicate priority numbers filter(duplicate_priority == &quot;FALSE&quot;) %&gt;% # remove duplicate priority numbers select(-priority) # drop uneccesary field While the above may appear initially appear complex it follows step 1 to 7 above. Because the data lacks a priority country and year field it extract these fields from the data to use in graphing as the next step. The key steps in arriving at accurate counts in the above process is trimming the separated fields to remove any leading and trailing white space. Note that the amount of cleaning required is likely to vary when working with data from different databases. The steps above reduce the dataset from 15,776 applications containing 23,382 priority numbers (after the exclusion of Not Available results) to 9,358 earliest priority numbers. We are now in a position to graph the data. For convenience we will continue to use R and the popular ggplot2 package. The results of a raw count are presented in Figure 3.1 Figure 3.1: Raw Graph of Trends in Priority Filings This is not generally what we will be expecting because it transpires that we have a long tail of low frequency records where the priority year is invalid such as 0001-01-01, or the date was not in the expected YYYY-MM-DD. In addition this test dataset includes historic records from the 19th Century that we will not in this case be interested in seeing. It is therefore sensible to filter the results to a more recent period. Figure 3.2 shows the effect of filtering the priority year to 1990 to 2017. Figure 3.2: Graph of Trends in Priority Filings showing the Priority Data Cliff This version of the graph brings us closer but note that the data falls off a cliff between 2015 and 2017. This is a characteristic of counts of patents by priority filings and you should always expect to see it. The reason it occurs is not because of a collapse in patent activity but because of the lag time between the filing of applications and their availability as publications in patent databases. The gap between the filing of an application and its publication is generally 18 months but it may be at least two years. This problem is referred to as timeliness in patent statistics. The safest option is to pull back to the date range between 2 - 3 years to avoid giving the impression of a collapse in activity. Figure 3.3 shows the effect of this approach. Figure 3.3: Graph of Trends in Priority Filings excluding the Data Cliff More advanced techniques for addressing the problem of timeliness were developed by Helene Dernis at the OECD and subsequently taken forward by Eurostat (Dernis 2007, de_Rassenfosse_2013). The key advantage of counts of the earliest priority filings is that they remove the duplication that is inherent in patent data and allows us to focus in on the underlying filing rate: that is to examine trends in filings linked to underlying investments in Research and Development. However, trends in the first filings of patent applications are not the whole story. Other types of patent counts focusing on applications, patent families and patent family members focus on the nature and geography of demand for patent rights. 3.5 Counting Applications One challenge for the patent analyst is that data on priority applications may not be readily available or accessible when preparing a report. Patent databases vary in the quality of priority data and in these circumstances the use of simple counts of patent applications, accompanied by an explanatory note are likely to be an appropriate alternative. Here we need to bear in mind That we need to use the application year That we will be counting distinct applications that may arise from the same underlying filing. Figure 3.4 shows trends in patent applications by application year. ## Warning: Removed 1 rows containing missing values (geom_path). Figure 3.4: Graph of Trends in Applications by Application Year In this case the data cliff (not shown) occurs from 2016 onwards. This reflects the fact that when compared with counts by the earliest priority year, counts by application year lean forward. Because these counts also capture the applications stemming from a priority, such as applications in more than one country, they will also be at a higher level. Figure 3.5 compares the two figures. Figure 3.6 zooms in to the figure for the period 2005 to 2015. Figure 3.5: Trends in First Filings and Patent Applications Figure 3.6 focuses in on the period 2007 to 2015 to more clearly see the divergences between the data. Figure 3.6: Trends in First Filings and Patent Applications As we might expect Figure 3.5 makes clear that counts of applications run parallel to trends in first filings. However, this is not the entire picture. Note the speed bump that appears between 2007 and 2010 starting with a downward inflexion in 2008 followed by an upward inflection and downward inflexion in 2010 reflecting a decrease then rapid increase and decrease in first filings. While the initial downward inflexion is displayed in the trend for applications the speed bump is replaced by a steadily increasing slope until 2013. What this reflects is the follow on multiplier effect of applications based on the underlying filings being published in multiple jurisdictions that disguises the temporary bottoming out of first filings over the same period before growth in filings accelerates dramatically. We can also see that in 2013 an inflexion occurs in filings and applications with the inflexion occurring at a higher document count for applications. In summary, the application rate runs broadly in parallel with the priority rate but it smooths out and disguises changes in the priority filing rate that are likely to more closely reflect underlying investments in research and development. 3.5.1 Mapping Publications So far we have focused on mapping trends using the earliest priority documents and application numbers. We will now examine what happens if we map patent publications using the data contained in the inpadoc family member field consisting of 49,508 publications linked to the applications and their priorities. Figure 3.7 shows the trend for counts of publications in the inpadoc family members field. Figure 3.7: Trends in Publications (INPADOC Family Members) We can now place this data which simply counts the number of publications within the INPADOC family members field into a graph with the counts by priority and applications as in Figure 3.8. Figure 3.8: Trends in Publications (INPADOC Family Members) We can see in Figure 3.8 that the difference between the patent publications linked to the applications and the first filings is dramatic. We will consider different definitions of patent families below. For the moment, the important observation here is that trends in the publication of INPADOC family members linked to the applications and priority filings do not closely match the pattern displayed by the applications and priority filings. What we are observing here is the multiplication effect of demand for patent rights in multiple countries around the world. Demand for patent rights, as manifest in the filing, pursuit and maintenance of patent rights in multiple countries is an expression of the importance of the underlying invention to the applicants expressed in their willingness to pay for the pursuit of patent protection in different jurisdictions. Whereas first filings of patent applications are a proxy indicator for investments in research and development, trends in patent publications are an indicator of the commercial importance of those inventions to the applicants expressed in willingness to pay the relevant fees for examination of applications and the maintenance of patent grants. As we will see below the size of a patent family is therefore an indicator of the importance of an underlying invention to the applicant. However, as we will now see, while the majority of attention in patent statistics focuses on counts of priority filings and applications, publication data provides a route to identifying trends in patent applications and grants on the country and instrument level. 3.6 Trends by Country using Publication Data In this section we illustrate the process for developing patent trends analysis at the country level using the drones data. However, it is important to emphasise that the drones dataset is not complete. A complete analysis would require the construction of a patent dataset that used searches for relevant jurisdictions in the appropriate languages using tools such as Patentscope CLIR (Cross Lingual Information Retrieval) which facilitates the translation of search terms into other languages. As such the drones data we will be working with is incomplete for national level analysis. However, bearing this major limitation in mind, it is nevertheless useful for illustrating methods, considering the issues that are likely to be encountered and how to deal with them. When seeking to develop analysis on the country level it is important to note that some countries and instruments will display high levels of activity (WO, EP, US, JP, CN and others) while others will display very low levels of activity. As a consequence, attempts to graph the data will results in a large number of countries appearing at the bottom of the graph. One approach to this is to simply focus on graphing the countries/instruments with the highest number of results. We will focus on mapping trends for the top countries and instruments. Figure 3.9 displays the trends in publications, as an indicator of demand, for the top countries and instruments. Figure 3.9: Trends in Publications using INPADOC Family data Figure 3.9 reveals that in terms of patent publication counts the United States is the lead country by a considerable margin, followed some distance behind by the PCT and the EPO. Note however, that this is not comparing like with like as the US data is confined to a single country whereas the EP and PCT are vehicles for the pursuit of protection in multiple countries. We can also see that the dominance of the US data in terms of counts of publications is compressing the data for the other main countries and instruments to the bottom of the graph. In practice, the difference is so marked that we would probably seek to separate out the data. We will address this in greater detail below. Patent publication data, in this case derived from INPADOC Family Member numbers is important because it allows for the analysis of trends in patent applications and patent grants using patent kind codes. As discussed above, one challenge with patent kind codes that describe publication levels is that their use has varied over time. Thus in the United States prior to 2001 patent documents were only published when granted and received kind code A (first publication level). After 2001 the United States began publishing patent applications as the first publication level and they received kind code A while kind code B is used for the second publication level (granted patents). This has two impacts on counts of patent data. First, as we see in Figure 3.9 the data for the United States appears to leap between 2000 and 2001. This does not reflect a leap in patent activity but is instead a reporting effect arising from the publication of both applicants and grants. Second, we cannot simply use the A and B kind codes to separate out trends in patent applications and grants for the United States because they refer to different types of publications over time. To address this we have created a field in the families table called kind-adjusted that has converted US kind code A documents to kind code B in the period before 2001. The original kind code is maintained in a field called kind_original as good practice when transforming the original data. Figure 3.10 displays trends in patent applications and grants based on this adjustment.9 Figure 3.10: Trends in US Patent Applications and Grants These raw counts of publications with kind code A for applications and kind code B for patent grants reveal two points. In the case of this data there appears to have been a spike in patent grants between 2000 and 2001 from 67 to 184 grants which may, or may not, be associated with the shift to the publication of patent applications from 2001 onwards. The second point is that we observe the start of the publication of patent grants from 2001 onwards with notable peaks and troughs suggesting that this graph would benefit from smoothing. However, for our purposes we can clearly see the point at which US data is transformed in scale by the publication of applications. The important point to bear in mind here is that in the period prior to 2001, US patent activity was under-reported relative to activity elsewhere because only data on grants was published. From 2001 the US harmonises with the rest of the world and we see an apparent jump in activity that is in fact a reporting effect. In considering the use of patent publication data (in this case arising from INPADOC family members) it is important to remember that data by publications also leans forward. Peaks and troughs in this data will in fact reflect changes in underlying filing activity from at least two years before. In addition, peaks and troughs will be affected by strategic behaviour by applicants such as the filing of continuation, continuation in part and divisional patent applications (see Hegde, Mowery, and Graham 2007 for discussion) along with administrative issues within patent offices that may affect the publication of patent documents. As this example suggests, significant caution is required when seeking to use publication data to map patent applications and grants in any given country. That is, it is important to investigate the use of kind codes over time for each country that is included in an analysis. For example, in a number of EPC member states, a regional European patent grant only becomes a national patent grant when it is translated. These documents are awarded kind code T. In EPC member states kind code T is therefore equivalent to a patent grant. We will now look at trends across the top 10 countries. In doing so we need to recall the major caveat that this data will be incomplete for drone technology in each country. However, to get a feel for this we will start simply by mapping trends in publications and then break the data down using kind codes. Because some of the countries in the top ten have relatively limited activity we will include a loess smoothing trend line rather thank linking the data points. The results are presented in Figure 3.11 and limited to the period 2000-2017 for ease of visibility. Figure 3.11: Publication Trends for Top Ten Countries (INPADOC Family Members) In considering Figure 3.11 note that the scale of activity (shown by the y axis for each country) reveals quite dramatic differences in activity for each country. We can also see that Australia and Germany display unusual patterns. This type of pattern typically reflects a relative lack of pattern in low frequency data. As such, this type of graph can assist with decision making in identifying the most significant sources of data to present to readers for analysis. In work on the development of the scientific and patent landscape for marine genetic resources for South East Asian countries a problem emerged where major peaks were encountered followed by zero or very low activity. Radical peaks and troughs in patent data typically suggest missing data. In the case of South East Asia it transpired that PATSTAT had very limited coverage of ASEAN national collections and thus presented a very partial view when compared with Derwent Innovation which includes the ASEAN national collections. As such, graphs of the type displayed above should be initially used for exploratory data analysis with a focus on the assessment of the completeness of the data (in this case we know that the data will be incomplete). Figure 3.11 also provides us with important clues on what we might expect when we seek to visualise patent trends by kind codes for these countries. That is we should expect to see erratic data or no real pattern for countries with lower counts. For illustration Figure 3.12 presents the breakout of the data for each country above using kind code A and B and excluding other types of document (e.g, Utility models and designs). Figure 3.12: Publication Trends for Top Ten Countries with Kind Code A and B A number of features emerge in Figure 3.12, In the case of the PCT we can see a small number of patent documents with Kind Code B. In practice there are two PCT documents in the dataset with Kind Code B. This is presumably a data entry mistake because WIPO does not issue documents with Kind Code B as the PCT has no second publication level. A second feature emerges in the case of Japan where the number of patent applications dips dramatically below the level of B documents before increasing dramatically. We would reasonably expect that the application rate would be higher than the grant rate. In practice, this issue will reflect the incomplete nature of the dataset we are working with. A third issue arises with Australia which exhibits a peak in activity around 2000/2001 and then collapses. One known issue with data from Australia is that around this period Australia recorded PCT designations as if they were actual applications leading to distortion of the statistics between approximately 2000 an 2003 [ref patstat forum]. In the case of Canada (CA) we observe activity for Kind code A but no activity for Kind code B. This illustrates the importance, as emphasised above, of examining the use of kind codes in individual countries that will be the focus for analysis. Canada uses Kind code C for patent grants while Kind Code B is used for reissue patents. The case of China (CN) which displays data for kind code B from 2010 onwards may suggest that there are limitations in the availability of patent grant data that require investigation. In the case of Germany (DE) this exposes the limitations of our dataset (which did not involve searching the German collection). While bearing this in mind, note that the data on patent grants (which exceeds those for applications) is reflecting the translation of EPC patent grants. In practice the landscape of Kind Codes for Germany is quite complicated and once again reveals the need to review Kind Codes with considerable care when developing this type of analysis. 3.7 Patent Families In the preceding sections we have moved from counting patent data by priority or first filings, to counting applications and then using patent publications to explore the issues involved in mapping trends in patent applications and grants on the country level. As we have seen when we move to the country level issues of data capture from the search strategy and the interpretation of Kind Codes become major issues. As part of this discussion we used patent publication data from INPADOC Family Members that are linked to the underlying first filings. We will now look at patent families and their uses in more detail. At its simplest a patent family is simply a grouping of patent documents based on a relationship or set of relationships. As we will see below that relationship can vary. However, for everyday purposes the following working definition has the benefit of being simple and easy to remember. At its simplest a patent family can be understood as a stack of documents published in any language anywhere in the world that share a common parent in the form of a priority number. As we will see, this simple working definition describes around 75% of patent families in the PATSTAT database. In practice, there are a number of different definitions of patent families. Simple first filing based families. These are families where members must share a priority number (Martinez 2010a). 2 DOCDB families. Similar to the above except that based on expert review at the EPO documents with the same technical content are added to the family. DOCDB refers to the EPO central documentation database (Martinez 2010a) INPADOC extended families. These families share the DOCDB definition but the definition is expanded so if document A shares a priority number with document B they are in the same family. However, if document C shares a priority with document B but not document A then document C will still be grouped in the family of document A.10 In addition, examiners may identify other technically related documents that are added to the family. INPADOC patent families are therefore larger than DOCDB simple families (see below). Triadic patent families (OECD definition for filings shared between the US, EP and JP). This is used by the OECD in patent analysis to refer to patent filings that are made in the United States, at the European Patent Office and in Japan. The aim of these families is to allow for analysis of the internationalisation of technology by neutralising the home bias created by the fact that most applications are made in national offices. This is achieved by focusing on those made at the three major offices (Dernis and Khan 2004; Criscuolo 2006; Sternitzke 2009). Derwent Patent families. A type of patent family used in the Derwent World Patent Index from Clarivate Analytics. This type of patent family relies on the identification of new priority filings that become the Basic patent for a patent family. Documents sharing that priority are classified as equivalents and become part of the patent family and includes continuation and continuations in part. In addition, what are called non-convention equivalents that do not share a priority but with the same technical content are added to the family and marked. This allows users to identify documents for the same invention that do not share a priority. PatBase defines its families as follows: &quot;A PatBase family contains all publications that share one or more common priority number(s). This includes continuations-in-part. If PatBase families become very large (100+ members) where possible these are broken down into sub-groups of simple families. A simple family is one where all priority numbers are shared. It is likely that this list of definitions of patent families is incomplete but it indicates the range of possible groupings. In practice, the most commonly encountered definitions of patent families are simple families, DOCDB families and INPADOC extended families. However, as we can see from the definitions above one challenge with patent families is that there appears to be an element of subjective judgement whereby examiners or database providers take decisions on the members of patent families. In addition patent database providers do not always clearly describe the process for determining patent families. This can make patent families confusing and the simple working definition provided above is designed to give clarity of focus. Research on patent families has been greatly enhanced by the creation in 2006 of the EPO World Patent Statistical Database (PATSTAT). In 2010 Catalina Martinez published an important OECD Working Paper entitled Insight into Different Types of Patent Families&quot; on the structure of patent families using PATSTAT data for the period between 1991 and 2009 (Martinez 2010a, 2010b). This study made a major contribution to clarifying the impact of different definitions of patent families using PATSTAT as an international baseline and also explored the structure of patent families. We will now briefly summarise and explore the main findings from this study. Martinez focuses on the important question of how to build patent families and identifies four types of linkages that can be used to build patent families: Paris Convention priorities Technical similarities (also called non-convention priorities, intellectual priorities or technical relations) Domestic priorities (e.g.continuations, continuations in part, provisionals, divisionals) PCT regional/national phase entries (Martinez 2010: 23) Each of these types of linkages is accompanied by a definition and whether the information is provided by the applicant as in Table 3.8 reproduced from Martinez below (Martinez, 2010. Table 7, 23) Table 3.8: Sources of the Building Blocks for Patent Families Type Definition Claimed by applicant in patent document Paris Convention priorities Allow a one year delay between first original filing and subsequent foreign filings by same applicant claiming the priority right (1883 Paris Convention). YES Technical similarities Relations among patent documents with similar scope, inventor and applicant names, that nevertheless lack common priority. An artificial priority link is assigned manually by the database producers. NO Domestic priorities Filed at the same office. They are mainly continuations, continuations in part and provisionals (the three of them only available at USPTO), and divisionals, which are available at most patent offices (1883 Paris Convention). YES National phase entries of PCT filings Entry into regional/national phases of PCT filings. YES As we can see in this table, the source of information for building patent families predominantly comes from the applicant except for the technical similarities. Technical similarities are identified by examiners based on their assessment of the scope, inventor and applicant names and result in an artificial priority link. As such, the identification of technical similarities is not purely subjective. Martinez then uses the EPO World Patent Statistical Database (PATSTAT) to quantify the impact of the use of the different linkages on the size of patent families for the period 1991 to 1999. Table 3.9 reproduces Table 9 from Martinez’s research. Table 3.9: Counts of families and applications in them, by source of family relations 1991-1999 (Martinez 2010a) Source 1 Families Source 2 Families Source 3 Families Source 4 Families Paris Convention Paris Convention + Domestic Continuations Paris Convention+ Domestic continuations + Technical similarities) Paris Convention + Domestic continuations + Technical similarities + PCT national phase entries year families members families members families members families members 1991 106850 567024 110371 610367 110856 614631 110745 614888 1992 107873 571499 113659 624205 114394 629235 114276 629538 1993 112351 602058 119014 655380 119656 659896 119533 660106 1994 116602 639485 123818 693431 124606 698404 124362 699194 1995 129535 722318 135946 761371 136702 766020 136405 766939 1996 146281 805300 152088 849307 152994 854422 152681 855240 1997 161060 874480 166277 914281 167220 919518 166857 920284 1998 173243 939352 179345 985989 180095 990508 179618 990914 1999 196972 1057368 204330 1102833 205222 1106929 204659 1107482 1991-1999 1250767 6778884 1304848 7197164 1311745 7239563 1309136 7244585 Note that Table 3.9 focuses on the earliest priorities and excludes singletons.b A number of important points emerge in Martinez’s analysis. The first of these is that “Paris Convention priorities alone make up more than 95%, which make them the most relevant patent linkage by far in the construction of extended patent families.” As such Paris Convention priorities are the foundation of patent families. The second major observation is that the number and size of families increases as the definition is expanded in the first three cases. The third case exactly matches with the widely used INPADOC extended patent family definition (Paris, domestic continuations and technical similarities). However, observe that the number of families in the final case in the table is lower in all cases than for the source 3 (INPADOC) even while the number of family members increases. The reason for this is that first three types create new independent families. In contrast, the final type consolidates families by revealing shared links through the Patent Cooperation Treaty. That is, the number of families falls because otherwise hidden linkages with the PCT become obvious (see Martinez 2010: 25). Using this data we can visualise the impact of different types of counts of families and family members. We will focus here on displaying the difference between the simple family definition and the INPADOC definition (source 3 above). Figure 3.13 trends in the number of patent families using the simple and INPADOC definitions. Figure 3.13: PATSTAT Trends in DOCDB Simple and INPADOC Extended Patent Families (Martinez 2010a) We can see here that the DOCDB simple families and the INPADOC family counts follow the same pattern except that the number of inpadoc families are consistently larger than the DOCDB simple families. Figure 3.14 places counts of the families and family members onto the same graph the difference between counting the number of families rather than the number of family members comes into focus. Figure 3.14: Trends in Patent Families (priority filings) and Family Members compared In considering this graph note that while the families count range is in the hundreds of thousands, with 205,222 INPADOC families in 1999, the equivalent count for INAPDOC family members was 1,106,929. Under both definitions this brings home the scale of the multiplier effects arising from the publication and republication of patent documents. We have seen a similar type of pattern in Figure 3.8 for the drones data where the number of patent family members accelerates away from the priority filings as publications multiply. Martinez also explores and quantifies the different structures of patent families in the period between 1991 and 1999 (see in particular Martinez 2010a). Martinez developed an algorithm to assess the structure of the INPADOC patent families discussed above and found that: “Applying the algorithm just described to the 1 311 745 INPADOC extended patent families with earliest priorities in the 1990s, as reported in PATSTAT September 2008, and excluding families formed by one patent document only (singletons), a total of 47 437 different family structures are identified. Among them, however, only a few structures are really popular: 86% of the structures represent just one family each, whereas only 10 structures represent 73% of all families and 25 represent 81%. In addition, more than half of the top 25 structures are made up of one earliest priority followed by several direct subsequent filings, what we will call “simple structures” from now onwards.&quot;11 The important point here is that while initially the structure of patent families may appear to be extremely diverse, with 47,437 different family structures, in practice 10 structures described 73% of the families and 25 structures accounted for 81%. This is a very significant finding because it informs us that the majority of the time the structure of patent families falls within a limited set. Furthermore, of the top 25 structures, over half are made up of a simple structure consisting of a single earliest priority followed by several direct filings. Martinez goes on to conclude that “…we have found that 75% of all INPADOC extended priority patent families with earliest priorities between 1991 and 1999 have a simple structure, consisting of one single first filing and its direct subsequent filings” (Martinez 2010a). The broader significance of this is because INPADOC extended families are the broadest category of common family types that 75% of other patent families will be of the single first filing and direct subsequent (child) filing type. From this we can reasonably conclude that the majority of patent families that we will ever encounter will be of the simple type (single priority followed by several direct filings). However as Martinez also notes “Complex families may favor specific technologies, countries or more valuable patents” (Martinez 2010: 17) so it is important to bear in mind that complex families while representing a much smaller proportion of the data may also be important. In considering the use of different types of family counts the most commonly encountered forms will be the DOCDB simple family types or the INPADOC family types. In the sections above we have graphed families (priority filings) and used raw family members to explore trends in different countries. However, as mentioned above the size of patent families is an indication of the importance of an invention to the applicants based on their willingness to pay fees for the stages of the procedure and for the maintenance of any granted patents in one or more jurisdiction. Table 3.10 displays the raw count of INPADOC family members across the drones dataset linked to the earliest priority number. Table 3.10: Top INPADOC Families earliest_priority application_number family_count AU19977991A 1997-07-15 JP200944799A 2009-02-26 2964 US13420236A 2012-03-14 US14253376A 2014-04-15 1819 US2013811981P 2013-04-15 US14253099A 2014-04-15 1819 US2001270625P 2001-02-23 EP2002714961A 2002-02-21 1440 US2011452418P 2011-03-14 US14024204A 2013-09-11 808 US2002387792P 2002-06-11 US13602510A 2012-09-04 808 US14064189A 2013-10-27 US14526503A 2014-10-28 371 US13158372A 2011-06-10 US14065419A 2013-10-29 371 US201364189A 2013-10-27 EP2014857043A 2014-10-28 371 US14065415A 2013-10-28 WO2014US62477A 2014-10-27 371 The top result in the drones dataset lists an earliest priority filing in 1997 and concerns a Methods for Manufacturing Inkjet Print Head using Multilayer Material Layer by Silverbrook Research in Australia involving Kia Silverbrook who has been described on Wikipedia as having been the worlds most prolific inventor.12 According to news reports Silverbrook Research went into administration in 2014.13. This is an example of noise in our drones dataset and a historic example, however the size of the INPADOC patent family indicates that the claimed invention was of great importance to the applicants. Table 3.11 displays the countries that have been the focus for the development of this family. Note that each document in the family is counted. Table 3.11: Top Family Countries for priority AU19977991A family country raw consolidated US 2116 2116 AU 334 292 SG 52 52 EP 119 49 JP 44 44 WO 40 38 CN 35 35 DE 38 31 IL 55 30 KR 30 30 AT 28 28 ZA 27 27 CA 43 26 NZ 2 2 ES 1 1 Table 3.11 shows the raw counts of family member documents for each country and the consolidated counts (with the kind codes removed to group by document identifier). The documents are ranked on the count of the consolidated family members. We can immediately see that while the applicant company was Australian the key target market was the United States followed by Australia, Singapore, Europe (through the European Patent Office) and Japan. By far the greatest intensity of family members is found in the United States and it transpires that these family members are clustered by date. Figure 3.15 shows US family member publications as a simple frequency plot over time. Figure 3.15: Frequency Plot for the Publication of US Family Members for priority number AU19977991A 1997-07-15 Figure 3.15 shows a strong clustering effect. In order to more clearly understand what is happening inside this plot Figure 3.16 displays the frequencies for US granted patents within the family over time (kind code B) Figure 3.16: Frequency Plot for Patent Grants among US Family Members for priority number AU19977991A 1997-07-15 What emerges here is that there are 1,086 US patent grants that can be traced to the single Australian priority filing.14 The earliest US patent grant in the set was published in March 2000 as US6041600A for the Utilization of quantum wires in MEMS actuators that claims priority to the Australian document. The latest patent grants in 2017 provide the explanation for what has been happening with the family members. The text of the most recent patent grant US9584681B2 for a Handheld Imaging Device Incorporating Multi-Core Image Processor in the description on related applications says: This application is a continuation of U.S. application Ser. No. 13/101,131 filed May 4, 2011, which is a continuation of U.S. application Ser. No. 10/656,791 filed Sep. 8, 2003, issued Jun. 7, 2011, as U.S. Pat. No. 7,957,009, which is a continuation application of U.S. application Ser. No. 09/922,274 filed Aug. 6, 2001, issued Sep. 9, 2003, as U.S. Pat. No. 6,618,117, which is a continuation-in-part application of U.S. application Ser. No. 09/113,053, filed Jul. 10, 1998, issued Mar. 26, 2002, as U.S. Pat. No. 6,362,868. Each of the above identified patents and applications and U.S. Pat. No. 6,238,044 are hereby incorporated herein by reference in their entirety. While we have not been able to review the entire portfolio of patent grants, a review of the five most recent documents suggests that the US members of this family have been constructed from a long series of continuation and continuation in part applications. Further analysis of this specific case is beyond the scope of the Handbook. However, as discussed in the recent in depth review of patent family research by Dechezleprêtre et. al. 2017 it highlights the strategic uses of the patent system with respect to continuation filings (Dechezleprêtre, Ménière, and Mohnen 2017). Lemley and Moore provide a critique of the use of continuations in the US system and focus on the extreme example of patent activity by a Jerome Lemelson in connection with bar code readers (Lemley and Moore 2003). They highlight that using continuations and continuations in part: “Inventors can keep an application pending in the PTO for years, all the while monitoring developments in the marketplace. They can then draft claims that will cover those developments. In the most extreme cases, patent applicants add claims during the continuation process to cover ideas they never thought of themselves, but instead learned from a competitor. The most egregious example is Jerome Lemelson, who regularly rewrote claims over the decades his patents were in prosecution in order to cover technologies developed long after he first filed his applications. Lemelson filed eight of the ten continuation patents with the longest delays in prosecution in our study. Those Lemelson patents spent anywhere from thirty-eight to more than forty-four years in the PTO.” (Lemley and Moore 2003) As Dechezleprêtre et. al. point out the aspects of US patent law that facilitated the specific strategic behaviour by this applicant have been abolished. However, continuations and continuations in part continue to feature as part of the US patent system. From the perspective of patent analytics, this example demonstrates that we are able to move from the use of patent family data to explore patent activity linked to a priority filing or set of priorities anywhere in the world. We are also able to identify the top ranking patent families and to explore the details of those families in individual countries. Simple techniques such as the use of a frequency plot over time help us to identify patterns in activity. In the case of Silverbrook we have seen that while the company reportedly went into administration in 2014, with a collapse in US family activity observable in the frequency plots above for that period, we then observe the issuance of patent grants from 2015 into 2017 (the end of our data). This suggests that this portfolio has been taken over (perhaps through the sale of the IP to a third party). To proceed further in the analysis of this case we would want to look at the legal status for the documents in the portfolio. Thus, a review of the legal status for the most recent patent grant US9584681B2 reveals that it is now owned by Google.15. In addition, as discussed by (Hall and Harhoff 2012) the analysis of patent renewal fees has an important role to play in analysis of the economic value of patent grants within a family portfolio. The discussion of patent families presented above points to the richness of research that is possible using patent family data. It is important to note that different definitions of patent families are important in patent analytics and may yield different insights. Thus, one criticism of INPADOC patent families is that they are too broad and a simpler more focused definition may be preferred. In other cases as in the work by the OECD the use of trilateral patent families is intended to promote international comparability by removing the home bias in patent data. The use of this type of definition is important for both comparability and identification of more important patents. Thus in the case of countries such as China, where filings are heavily focused on the national level, the selection of patent families with international members can facilitate the analysis of cases where Chinese inventors and applicants may be seeking to invest in external markets. In closing this discussion it is important to emphasise that patent families continue to be a very active focus of research in economics and innovation studies. As the most recent review of the literature by Dechezleprêtre et. al. 2017 has highlighted to date the main focus in this literature has been on using family size as the indicator of value (focusing on the number of countries represented in a family) the number of filings in the priority country along with the time span between the first and last filings within a family also offer insights into patent value (Dechezleprêtre, Ménière, and Mohnen 2017). As such, the discussion presented above presents a starting point for engaging with this increasingly rich literature. 3.8 Forecasting Patent Activity TBD References "],
["patstat.html", "Chapter 4 PATSTAT (placeholder)", " Chapter 4 PATSTAT (placeholder) This is a placeholder, please come back later "],
["indicators.html", "Chapter 5 Indicators (placeholder)", " Chapter 5 Indicators (placeholder) This is a placeholder, please come back later "],
["textmining.html", "Chapter 6 Text Mining (placeholder)", " Chapter 6 Text Mining (placeholder) This is a placeholder, please come back later "],
["geocoding.html", "Chapter 7 Geocoding 7.1 Lookup the Records 7.2 Reviewing Initial Results 7.3 Preprocess the Data and Rerun the Query 7.4 Round Up", " Chapter 7 Geocoding In this Chapter we will explore geocoding, Geocoding is the process of turning location names such as organisation names or addresses into georeferences in the form of latitude and longitude coordinates for representation on a map.16 Geocoding is a relatively recent and popular way to map activity in geographic space, such as research organisations, patent applicants and patent inventors. Basic geocoding such as clustering records by country can be performed using country codes or country names in free tools such as Tableau Public. This chapter addresses a more advanced form of geocoding using web services, and specifically the Google Maps API to geocode thousands of organisation names from Web of Science data. The Google Maps API can be accessed in a range of programming languages such as Python or R. We will focus on illustrating the issues involved in geocoding sing the placement, ggmap, and googleway packages in R. We will work with some raw data from Clarivate Analytics Web of Science database of scientific literature. Many universities have access to Web of Science and it is a very important tool in fields such as bibliometrics/scientometrics. Geocoding is the process of taking a name and address and looking up the geographic coordinates expressed in latitude and longitude. This is normally done using a web service. There are plenty of example walkthroughs on how to do this. However, many of them start with data that is already clean. We will be working with data that is really rather messy. What we are attempting to do is to obtain the addresses and coordinates from the author affiliations field in Web of Science records. Our dataset is from a set of queries for scientific literature for South East Asia (ASEAN) countries that involve marine organisms. We have a table with 5,206 author affiliation details containing the names of organisations, the city and the country. This data is not clean and contains multiple minor variations of the same organisation name. The data also contains variations in geographic locations such as references to a district within a city rather than the name of the city itself. To follow the walk through you can download the data from Github here. It simply contains the author affiliation name and a count of the number of records. One of the issues with Web of Science data is that the names of organisations are abbreviated/stemmed (so that University becomes Univ, Institute becomes Inst and so on and so on). Until recently this made geocoding a significant headache. However, as we will see below the Google Maps API now seems to do a very good job of handling these issues but considerable care is needed when interpreting the results. In this Chapter we will go step by step through the process of geocoding and deal with the issues we encounter along the way. At the end of the article we will pull the code together to identify a more efficient way to deal with geocoding Web of Science and similar data. By the end of this Chapter you will be familiar with what geocoding is and how to carry out geocoding using the placement, ggmap and googleway packages in R with RStudio. You will also be familiar with the Google Maps API and be able to identify and retrieve missing data using packages from the tidyverse. We will take what we learned and combine it into more efficient code for solving the problem and finish off with a quick map of the results. 7.0.1 Getting Started If you are new to R and RStudio then first we need to get set up. To install R for your operating system choose the appropriate option here and install R. Then download the free RStudio desktop for your system here. We will be using a suite of packages called the tidyverse that make it easy to work with data. When you have installed and opened RStudio run these lines in your console to install the packages that we will be using. install.packages(&quot;tidyverse&quot;) install.packages(&quot;placement&quot;) install.packages(&quot;devtools&quot;) install.packages(&quot;usethis&quot;) install.packages(&quot;googleway&quot;) For ggmap we will load the latest version 2.7 that includes register_google() for authentication and install it from github as follows. devtools::install_github(&quot;dkahle/ggmap&quot;) Next load the libraries. library(tidyverse) library(ggmap) library(placement) library(usethis) library(googleway) You will now see a range of messages as the packages are loaded. You should now be good to go. If you would like to learn more about R then try the excellent DataCamp online courses or read Garrett Grolemund and Hadley Wickham’s R for Data Science. Learning to do things in R will make a huge difference to your ability to work with patent and other data and to enjoy the support of the R community in addressing new challenges. There is never a better time to start learning to do things in R than right now. The placement, ggmap and recent googleway packages all provide functions for geocoding with the Google Maps API. The placement package by Derek Darves was created in 2016 and provides straightforward access to the Google Maps API and additional tools for address cleaning, calculating distances and driving times. As Derek explains here. I found it remarkably easy to use and it does not require any complicated code. The function we will be using is geocode_url() and geocode_pull(). That is basically it. While placement mainly focuses on geocoding, ggmap is a bigger package for mapping in R that includes geocoding. The package is a complement to ggplot2 and a Data Camp course by Charlotte Wickham Working with Geospatial Data in R will get you started in no time with ggmap and other mapping packages. As we will see below, I ran in to some tricky issues when trying to geocode with ggmap and you may also want to give googleway a try. We will mainly use the placement package because I like the simplicity of the package, but which you use will depend on your purpose and you will probably want to experiment with the wider functionality of ggmap or the more recent googleway. 7.0.2 Getting set up with the Google Maps API To use the Google Maps API you will need to: Sign in to a Google account Get a free API key from here. This involves pressing the Get a Key button and creating a project (app) that you will query by following these steps. Create a new project and wait a short while while Google spins it up. You will then see your API key. Note that you will see a link to restrict access to your API. It is a good idea to follow this and use your IP address to limit access to your IP address under Application restrictions. This will prevent other people from using the account if they discover the API key. We will not go down that route right now. Take a copy of your API key (say into a text file in R Studio). What you do next is up to you. Save the text file somewhere sensible and copy it into the functions below when needed. With usethis either: usethis::edit_r_environ() to open your local environment file and enter something like GOOGLE_MAPS_KEY=“yourkey” and then restart R. You will be able to access the key using Sys.getenv(&quot;GOOGLE_MAPS_KEY&quot;). usethis::edit_r_profile() and enter google_maps_key=“your key”, inside the existing options() chunk, save and restart R. Call the key with getOption(&quot;google_maps_key&quot;) For discussion on the above try reading the R startup section of Efficient R Programming or follow the very useful ROpenSci instructions. usethis makes life much easier because it knows where the files are! We will go with the usethis::edit_r_environ() environment option, so let’s store the key in our working environment for the moment using the imaginatively named key. key &lt;- Sys.getenv(&quot;GOOGLE_MAPS_KEY&quot;) 7.0.3 Using the API Note that API queries are limited to a free 2500 per day. It costs 50 cents per 1000 queries after that. As this is not expensive we signed up for a billing account to run the full list. As we will see below signing up for an API key is a good idea to avoid problems with the return resulting from pressure on the free service. When you sign up for the API key you still get the 2500 results but make sure you put your API key somewhere safe and do not make it public. Below we will briefly show how to use the placement, ggmap and newer googleway packages to retrieve geocode data. Unfortunately the return from the Google API with placement also includes a column called input_url. I say unfortunate because the input_url includes your private API key! So, if you are planning to make any of this data public you should exclude the input_url column. 7.0.4 The Source Data Next let’s take a quick look at the source data. When we send the addresses to the Google Maps API with placement it will return the original search terms in a column called locations. To make our life easier we renamed the original column in our source dataset. Note that the records field refers to the number of publications associated with an address and will allow us to size dots on any map we produce with the results. We can import the data directly from Github. affiliation_records &lt;- read_csv(&quot;https://github.com/wipo-analytics/data-handbook/raw/master/affiliation_records.csv&quot;) head(affiliation_records) ## # A tibble: 6 x 3 ## records locations id ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; ## 1 1 AAHL, Vic, Australia 1 ## 2 1 AAHRI, Bangkok, Thailand 2 ## 3 1 Aarhus Univ Biosci, Roskilde, Denmark 3 ## 4 1 Aarhus Univ Hosp, Aarhus, Denmark 4 ## 5 13 Aarhus Univ, Aarhus C, Denmark 5 ## 6 3 Aarhus Univ, Aarhus, Denmark 6 7.1 Lookup the Records In this section we will look up some of the records with each of the three packages to show how easy it is. Purely from personal preference we will use placement for the rest of the work. 7.1.1 Using placement The placement package can do more than we will attempt here. For example, you can attempt address cleaning or calculating driving distances with placement. For our purposes the main event is the geocode_url() function, We pass the data in the locations column to the function along with the authentication route and the private key. The clean = TRUE argument applies the address_cleaner function before encoding the URL to send to the API. The default is set to TRUE and you may want to experiment with setting this value to FALSE. We also add the date of search as it is always useful to know when we carried out the search and we set verbose to TRUE to receive more information. Note that other arguments such as dryrun can be useful for debugging problem addresses. Note that the key can be entered directly into geocode_url() as privkey = Sys.getenv(&quot;GOOGLE_MAPS_KEY&quot;). However, I found that this sometimes returned an error message on long runs. For that reason we might copy it into our local environment (and be careful not to expose it). key &lt;- Sys.getenv(&quot;GOOGLE_MAPS_KEY&quot;) library(placement) coordaffil &lt;- geocode_url(affiliation_records$locations, auth = &quot;standard_api&quot;, privkey = key, clean = TRUE, add_date = &#39;today&#39;, verbose = TRUE) 7.1.2 Using ggmap We can perform the same lookup using ggmap and the geocode() function. Note that the function defaults to the free allocation of 2500 queries. There are options to return “latlon” and “latlona”&quot; or “more” or “all”. In the case of “all” this returns a list with entries of differing lengths that you will need to wrangle. In general use latlon, latlona or more as this will return a data frame. Here we will just test 100 records. geocode() does not return the input URL with our private key (which is good). library(ggmap) coord_ggmap &lt;- geocode(location = affiliation_records$locations[1:100], output = &quot;more&quot;, source = &quot;google&quot;, messaging = FALSE) When using ggmap I encountered a significant number of OVER_QUERY_LIMIT entries in the return. Why is something of a mystery although as discussed here this may because we are sharing the call to the free service with others. It is therefore better to get a key if you are going to be using this service. To authenticate using ggmap (2.7 only) create a key based on the key in your environment file. Pass it to register_google() and then you are ready to make the call. key &lt;- Sys.getenv(&quot;GOOGLE_MAPS_KEY&quot;) register_google(key = key) It will now work smoothly. library(ggmap) ggmap1 &lt;- geocode(location = affiliation_records$locations[201:300], output = &quot;more&quot;, source = &quot;google&quot;, messaging = FALSE) This overcame the limitation and returned a data.frame with 100 entries. ggmap1 %&gt;% select(1:4) %&gt;% head() ## lon lat type loctype ## 1 -93.631913 42.03078 locality approximate ## 2 3.707011 51.05376 establishment rooftop ## 3 -1.386919 50.90853 establishment geometric_center ## 4 142.384141 43.72986 establishment rooftop ## 5 142.384141 43.72986 establishment rooftop ## 6 127.680932 26.21240 administrative_area_level_1 approximate 7.1.3 Using Googleway An alternative to placement or ggmap is also available using the googleway package. googleway includes access to the Google APIs for directions, distance, elevation, timezones, places, geocoding and reverse geocoding and so has a wider set of uses. However, googleway is expecting an address field of length 1 (meaning it takes one address at a time) whereas placement and ggmap are vectorised. The return from googleway returns a list object containing a data frame with the results and the status of the return. Here is one quick example. library(googleway) googleway &lt;- google_geocode(address = &quot;Aarhus Univ Biosci, Roskilde, Denmark&quot;, key = Sys.getenv(&quot;GOOGLE_MAPS_KEY&quot;), simplify = TRUE) For long lists we would therefore need to use an approach such as lapply() or purrr::map() to make the call as a set and then look at ways to bind the results together. googleway2 &lt;- purrr::map(affiliation_records$locations[1:2], google_geocode, key = Sys.getenv(&quot;GOOGLE_MAPS_KEY&quot;), simplify = TRUE) As this makes clear, you have at least three choices for geocoding and which you prefer will depend on your needs. I found ggmap rather awkward because the existing CRAN version (2.6) does not provide the register_google() function in the long standing 2.7 development version. While this is a bit awkward ggmap provides some very powerful features that you will want to use. On the other hand googleway would involve some more work to vectorise over the list as we started exploring above. placement on the other hand is fine with the only disadvantage being the return of the API key in the input URL that we have to remember. 7.2 Reviewing Initial Results When we originally started working with the Google API in 2017 the API returned 3,937 results from the 5,206 names. This then required a lot of additional work to retrieve the remaining numbers by cleaning up abbreviations and country names. However, the Google Maps API seems to have improved rather radically in the meantime. Let’s take a look at the issues that can arise with the return from the Google Maps API. For the moment we will focus on the completeness of the data revealed in status and error messages. coordaffil %&gt;% select(location_type, status, error_message) %&gt;% head() ## location_type status error_message ## 1 ROOFTOP OK ## 2 GEOMETRIC_CENTER OK ## 3 ROOFTOP OK ## 4 GEOMETRIC_CENTER OK ## 5 ROOFTOP OK ## 6 ROOFTOP OK The return from placement is a data.frame that is exactly the same length as our input. What we need to watch out for are the entries in the status column and the error message column. Here we need to be cautious because most of the time the API returns either “OK” or “ZERO_RESULTS”. However, there are additional status codes listed here and they are also listed in the documentation for geocode_url(). They are: “OK” “ZERO_RESULTS” “OVER_QUERY_LIMIT” “REQUEST_DENIED” “INVALID_REQUEST” “UNKNOWN_ERROR” “CONNECTION_ERROR” (added) When running a long set of addresses the CONNECTION_ERROR can creep into the data, so be aware of this. We can now join our data sets together. We will use left_join() for convenience and specify the column to join on as the shared locations column. results &lt;- dplyr::left_join(affiliation_records, coordaffil, by = &quot;locations&quot;) We can identify the results found so far by filtering on the status field which will show “OK” where there is a return and “ZERO_RESULTS” where the geocoding did not work: results %&gt;% filter(., status == &quot;OK&quot;) ## # A tibble: 5,187 x 10 ## records locations id lat lng location_type formatted_addre… ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 AAHL, Vi… 1 -38.2 144. ROOFTOP 5 Portarlington… ## 2 1 AAHRI, B… 2 13.8 101. GEOMETRIC_CE… 50, กรมประมง, ถ… ## 3 1 Aarhus U… 3 56.2 10.2 ROOFTOP Nordre Ringgade… ## 4 1 Aarhus U… 4 56.2 10.2 GEOMETRIC_CE… Nørrebrogade, 8… ## 5 13 Aarhus U… 5 56.2 10.2 ROOFTOP Nordre Ringgade… ## 6 3 Aarhus U… 6 56.2 10.2 ROOFTOP Nordre Ringgade… ## 7 1 Abasyn U… 7 34.0 71.6 GEOMETRIC_CE… Ring Road, Char… ## 8 1 Abdul Wa… 8 34.2 72.0 GEOMETRIC_CE… Nowshera Mardan… ## 9 1 Abertay … 9 56.5 -2.97 GEOMETRIC_CE… Bell St, Dundee… ## 10 1 Aberystw… 10 52.4 -4.07 GEOMETRIC_CE… Penglais Campus… ## # ... with 5,177 more rows, and 3 more variables: status &lt;chr&gt;, ## # error_message &lt;chr&gt;, geocode_dt &lt;date&gt; For the results that were not found it is safest not to simply filter for ZERO RESULTS but instead to filter for anything that is not OK using !=. This can save on endless hours of confusion where you have multiple messages in the status column. lookup &lt;- results %&gt;% filter(., status != &quot;OK&quot;) nrow(lookup) ## [1] 19 So, we have 19 records with no results. That is pretty good from just over 5000 results. lookup %&gt;% select(-id) ## # A tibble: 19 x 9 ## records locations lat lng location_type formatted_addre… status ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2 Aomori P… NA NA &lt;NA&gt; &lt;NA&gt; ZERO_… ## 2 1 FOOD CRO… NA NA &lt;NA&gt; &lt;NA&gt; ZERO_… ## 3 2 Hunan Ag… NA NA &lt;NA&gt; &lt;NA&gt; ZERO_… ## 4 1 Hunan Fi… NA NA &lt;NA&gt; &lt;NA&gt; ZERO_… ## 5 1 Hunan Un… NA NA &lt;NA&gt; &lt;NA&gt; ZERO_… ## 6 2 Indonesi… NA NA &lt;NA&gt; &lt;NA&gt; ZERO_… ## 7 1 Inst Oce… NA NA &lt;NA&gt; &lt;NA&gt; ZERO_… ## 8 1 Inst Oce… NA NA &lt;NA&gt; &lt;NA&gt; ZERO_… ## 9 6 Inst Oce… NA NA &lt;NA&gt; &lt;NA&gt; ZERO_… ## 10 2 ISME, Ok… NA NA &lt;NA&gt; &lt;NA&gt; ZERO_… ## 11 1 Kitasato… NA NA &lt;NA&gt; &lt;NA&gt; ZERO_… ## 12 1 Main Off… NA NA &lt;NA&gt; &lt;NA&gt; ZERO_… ## 13 1 Nha Tran… NA NA &lt;NA&gt; &lt;NA&gt; ZERO_… ## 14 1 Okinawa … NA NA &lt;NA&gt; &lt;NA&gt; ZERO_… ## 15 1 Ryukoku … NA NA &lt;NA&gt; &lt;NA&gt; ZERO_… ## 16 1 UNIV WES… NA NA &lt;NA&gt; &lt;NA&gt; ZERO_… ## 17 6 Vietnam … NA NA &lt;NA&gt; &lt;NA&gt; ZERO_… ## 18 1 VNIO, Nh… NA NA &lt;NA&gt; &lt;NA&gt; ZERO_… ## 19 1 Xi Consu… NA NA &lt;NA&gt; &lt;NA&gt; ZERO_… ## # ... with 2 more variables: error_message &lt;chr&gt;, geocode_dt &lt;date&gt; When dealing with thousands of records it is often a good idea to add a cut off threshold. For example we can see above that with two exceptions the entries are all for 1 or 2 records. As these will be barely visible on a map you may want to set a cut off point to focus in on the more important records. However, the lookup table highlights an issue that the Google Maps API previously struggled to deal with: abbreviations. When working with scientific literature abbreviations in author affiliations along with acronyms are common. So, lets look at how to deal with that. 7.2.1 Tackling Abbreviations Here we have created a simple file containing some of the major Web of Science organisation abbreviations and their matches. It is probably not complete but is a good start. Next we added a column with word boundaries that we will use to find and replace the abbreviations. You can download the the file directly from Github. wos_abbreviations &lt;- read_csv(&quot;https://github.com/wipo-analytics/data-handbook/raw/master/wos_abbreviations.csv&quot;, col_types = cols(abbreviation = col_character(), text = col_character())) A simple word boundary regular expression was added to assist with matching. wos_abbreviations$regex &lt;- paste0(&quot;\\\\b&quot;, wos_abbreviations$abbreviation, &quot;\\\\b&quot;) ## # A tibble: 6 x 3 ## abbreviation text regex ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Univ University &quot;\\\\bUniv\\\\b&quot; ## 2 Natl National &quot;\\\\bNatl\\\\b&quot; ## 3 Inst Institute &quot;\\\\bInst\\\\b&quot; ## 4 Sci Science &quot;\\\\bSci\\\\b&quot; ## 5 Ctr Centre &quot;\\\\bCtr\\\\b&quot; ## 6 Res Research &quot;\\\\bRes\\\\b&quot; To replace the abbreviations we will want to temporarily separate out the city and the country names in the locations column. This helps us to avoid transforming them by accident. We will bring the edited version back together later. Web of Science data uses a comma to separate out the entities and so we use that in a call to separate. We also keep the original column by specifying remove = FALSE as the default removes the input column. lookup &lt;- lookup %&gt;% separate(., locations, c(&quot;organisation&quot;, &quot;city&quot;, &quot;country&quot;), sep = &quot;,&quot;, remove = FALSE) ## # A tibble: 6 x 6 ## records locations organisation city country id ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 2 Aomori Prefectural A… Aomori Prefectural… &quot; Aom… &quot; Japan&quot; 161 ## 2 1 FOOD CROPS RES INST,… FOOD CROPS RES INST &quot; HAI… &quot; VIETNA… 1215 ## 3 2 Hunan Agr Univ, Huna… Hunan Agr Univ &quot; Hun… &quot; People… 1521 ## 4 1 Hunan Fisheries Sci … Hunan Fisheries Sc… &quot; Hun… &quot; People… 1522 ## 5 1 Hunan Univ Chinese M… Hunan Univ Chinese… &quot; Hun… &quot; People… 1523 ## 6 2 Indonesian Inst Sci,… Indonesian Inst Sci &quot; Amb… &quot; Indone… 1597 Next we want to iterate over the list of our organisation names and replace the abbreviations. There are a variety of ways to do that such as the qdap package function multigsub() or mgsub(). We like qdap a lot but installation of the package can be a bit awkward due to a dependency on rJava.17 Instead we are going to use a simple for loop (although a purrr solution would be an improvement). replaceabbr &lt;- function(pattern, replacement, var) { replacement &lt;- rep(replacement, length(pattern)) for (i in seq_along(pattern)) { var &lt;- gsub(pattern[i], replacement[i], var) } var } One issue with cleaning names is capitalisation. For example, in our wos abbreviations file we have used Univ as the most common abbreviation for University. However, this will not match UNIV and so we will be better off regularising the text. A common convention is to convert everything to lower case using tolower() at the start of working with the data. Here we don’t want to do that. We will use the extremely useful stringr package to convert the organisation name to to title case in a new field that we will call organisation_edited. The reason that we are not editing our original column is that at some point we will want to join the table back on to our original dataset…so we don’t want to touch our original column. We will do this using mutate() from dplyr(). lookup &lt;- lookup %&gt;% mutate(organisation_edited = str_to_title(.$organisation)) lookup %&gt;% select(organisation_edited) ## # A tibble: 19 x 1 ## organisation_edited ## &lt;chr&gt; ## 1 Aomori Prefectural Agr &amp; Forestry Res Ctr ## 2 Food Crops Res Inst ## 3 Hunan Agr Univ ## 4 Hunan Fisheries Sci Inst ## 5 Hunan Univ Chinese Med ## 6 Indonesian Inst Sci ## 7 Inst Oceanog Vast ## 8 Inst Oceanog ## 9 Inst Oceanog ## 10 Isme ## 11 Kitasato Univ ## 12 Main Off Educ &amp; Teaching Area ## 13 Nha Trang Inst Oceanog ## 14 Okinawa Prefectural Fisheries &amp; Ocean Res Ctr ## 15 Ryukoku Univ ## 16 Univ Westminster ## 17 Vietnam Acad Sci &amp; Technol ## 18 Vnio ## 19 Xi Consultancy Next, we transform the abbreviations using replaceabbr. lookup$organisation_edited &lt;- replaceabbr(wos_abbreviations$regex, wos_abbreviations$text, lookup$organisation_edited) lookup %&gt;% select(organisation_edited) ## # A tibble: 19 x 1 ## organisation_edited ## &lt;chr&gt; ## 1 Aomori Prefectural Agriculture &amp; Forestry Research Centre ## 2 Food Crops Research Institute ## 3 Hunan Agriculture University ## 4 Hunan Fisheries Science Institute ## 5 Hunan University Chinese Medical ## 6 Indonesian Institute Science ## 7 Institute Oceanography Vast ## 8 Institute Oceanography ## 9 Institute Oceanography ## 10 Isme ## 11 Kitasato University ## 12 Main Office Education &amp; Teaching Area ## 13 Nha Trang Institute Oceanography ## 14 Okinawa Prefectural Fisheries &amp; Ocean Research Centre ## 15 Ryukoku University ## 16 University Westminster ## 17 Vietnam Academy Science &amp; Technology ## 18 Vnio ## 19 Xi Consultancy This is not perfect, for example we encounter issues with Agriculture and Agricultural and so on. We also encounter issues of capitalisation in the city and the country field that we are presently ignoring. However, it is good enough for the time being. Rather than focus on resolving a small number of remaining items the next step is to reunite the fields we separated into a field we will call locations edited using the tidyr unite function. lookup &lt;- lookup %&gt;% unite(., locations_edited, c(organisation_edited, city, country), sep = &quot;,&quot;, remove = FALSE) lookup %&gt;% select(organisation, city, country, locations_edited) ## # A tibble: 19 x 4 ## organisation city country locations_edited ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Aomori Prefectural A… &quot; Aomor… &quot; Japan&quot; Aomori Prefectural Agricultur… ## 2 FOOD CROPS RES INST &quot; HAI H… &quot; VIETNA… Food Crops Research Institute… ## 3 Hunan Agr Univ &quot; Hunan&quot; &quot; People… Hunan Agriculture University,… ## 4 Hunan Fisheries Sci … &quot; Hunan&quot; &quot; People… Hunan Fisheries Science Insti… ## 5 Hunan Univ Chinese M… &quot; Hunan&quot; &quot; People… Hunan University Chinese Medi… ## 6 Indonesian Inst Sci &quot; Ambon&quot; &quot; Indone… Indonesian Institute Science,… ## 7 Inst Oceanog VAST &quot; Nha T… &quot; Vietna… Institute Oceanography Vast, … ## 8 Inst Oceanog &quot; Nha T… &quot; Vietna… Institute Oceanography, Nha T… ## 9 Inst Oceanog &quot; Nha T… &quot; Vietna… Institute Oceanography, Nha T… ## 10 ISME &quot; Okina… &quot; Japan&quot; Isme, Okinawa, Japan ## 11 Kitasato Univ &quot; Aomor… &quot; Japan&quot; Kitasato University, Aomori, … ## 12 Main Off Educ &amp; Teac… &quot; Tehra… &quot; Iran&quot; Main Office Education &amp; Teach… ## 13 Nha Trang Inst Ocean… &quot; Khanh… &quot; Vietna… Nha Trang Institute Oceanogra… ## 14 Okinawa Prefectural … &quot; Okina… &quot; Japan&quot; Okinawa Prefectural Fisheries… ## 15 Ryukoku Univ &quot; Okina… &quot; Japan&quot; Ryukoku University, Okinawa, … ## 16 UNIV WESTMINSTER &quot; LONDO… &quot; ENGLAN… University Westminster, LONDO… ## 17 Vietnam Acad Sci &amp; T… &quot; Nha T… &quot; Vietna… Vietnam Academy Science &amp; Tec… ## 18 VNIO &quot; Nha T… &quot; Vietna… Vnio, Nha Trang, Vietnam ## 19 Xi Consultancy &quot; Delft&quot; &quot; Nether… Xi Consultancy, Delft, Nether… Note that rather than creating a separate character vector we made life easier by simply adding locations_edited to our lookup data.frame (because the vectors are of the same length) using unite(). 7.2.2 Lookup edited names We now send the cleaned up version off to the Google API. library(placement) coordlookup &lt;- geocode_url(lookup$locations_edited, auth = &quot;standard_api&quot;, privkey = key, clean = TRUE, add_date = &#39;today&#39;, verbose = TRUE) Let’s take a look. coordlookup %&gt;% select(locations, status) ## locations ## 1 Aomori Prefectural Agriculture &amp; Forestry Research Centre, Aomori, Japan ## 2 Food Crops Research Institute, HAI HUNG, VIETNAM ## 3 Hunan Agriculture University, Hunan, Peoples R China ## 4 Hunan Fisheries Science Institute, Hunan, Peoples R China ## 5 Hunan University Chinese Medical, Hunan, Peoples R China ## 6 Indonesian Institute Science, Ambon, Indonesia ## 7 Institute Oceanography Vast, Nha Trang, Vietnam ## 8 Institute Oceanography, Nha Trang City, Vietnam ## 9 Institute Oceanography, Nha Trang, Vietnam ## 10 Isme, Okinawa, Japan ## 11 Kitasato University, Aomori, Japan ## 12 Main Office Education &amp; Teaching Area, Tehran, Iran ## 13 Nha Trang Institute Oceanography, Khanh Hoa Prov, Vietnam ## 14 Okinawa Prefectural Fisheries &amp; Ocean Research Centre, Okinawa, Japan ## 15 Ryukoku University, Okinawa, Japan ## 16 University Westminster, LONDON W1M 8JS, ENGLAND ## 17 Vietnam Academy Science &amp; Technology, Nha Trang, Vietnam ## 18 Vnio, Nha Trang, Vietnam ## 19 Xi Consultancy, Delft, Netherlands ## status ## 1 ZERO_RESULTS ## 2 ZERO_RESULTS ## 3 OK ## 4 OK ## 5 OK ## 6 OK ## 7 ZERO_RESULTS ## 8 OK ## 9 OK ## 10 ZERO_RESULTS ## 11 ZERO_RESULTS ## 12 OK ## 13 ZERO_RESULTS ## 14 OK ## 15 OK ## 16 OK ## 17 OK ## 18 ZERO_RESULTS ## 19 ZERO_RESULTS So, 8 of our revised names have failed to produce a return. In some cases this is a little surprising. For example the private Kitasato University would be expected to come up, but the reference to Aomori seems to have confused the mapper (as the University is listed as located in Minato). In the case of the Institute Oceanography Vast we can see that there is duplication (Vast refers to the Vietnam Academy of Science and Technology as the parent organisation of the institute) with the second and third entries being recognised. Other variants such as Nha Trang Institute Oceanography, Khanh Hoa Prov, Vietnam and the acronym Vnio, Nha Trang, Vietnam are also missed. How far you want to push with fixing addresses is up to you and will depend on your purposes. As mentioned above, to avoid a long tail of unresolved addresses for low frequency data you may want to use a cut off on the number of records. 7.2.3 Bringing the data together To join the data back together we need to do some tidying up on the lookup and coordlookup table first. Recall that we sent edited names to Google and those were returned as locations. This means that they will not match with the names in our original table. We also created some additional columns. To create tables that will match the original table we need to tidy up by: selecting the original columns in lookup plus locations_edited (our join field) renaming locations to locations_edited in the lookup results (the join field) join the tables drop the locations-edited column lookup &lt;- lookup %&gt;% select(records, locations, locations_edited, id) coordlookup &lt;- coordlookup %&gt;% rename(locations_edited = locations) res &lt;- left_join(lookup, coordlookup, by = &quot;locations_edited&quot;) %&gt;% select(-locations_edited) To join the data back together we now need to do two things. First we filter the results from the original search to those that are status == &quot;OK&quot; and then bind the res table to the end. results_complete &lt;- results %&gt;% filter(., status == &quot;OK&quot;) %&gt;% bind_rows(., res) We will write the results to an Excel and csv file that we can use in other programmes such as Tableau for mapping (we will briefly look at mapping with R below). writexl::write_xlsx(results_complete, path = &quot;asean_geocode_complete.xlsx&quot;) write_csv(results_complete, path = &quot;asean_geocode_complete.csv&quot;) We now have a complete set of geocoded results with 5,198 locations from 5,206. That is pretty good. However, having obtained the geocoded data and joined it onto our original data.frame we now need to look at the quality of the return. 7.2.4 Assessing the Quality of Geocoding So far we have focused on getting geocoded data without really looking at it. To assess the quality of the data that has been returned we should take a look at the location type field. The API documentation for these entries can be found here and in the geocode_url() documentation. results_complete %&gt;% drop_na(location_type) %&gt;% count(location_type, sort = TRUE) %&gt;% mutate(prop = prop.table(n)) ## # A tibble: 3 x 3 ## location_type n prop ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 ROOFTOP 2155 0.415 ## 2 GEOMETRIC_CENTER 1848 0.356 ## 3 APPROXIMATE 1195 0.230 The API documentation fills us in on what is going on here. &quot;location_type stores additional data about the specified location. The following values are currently supported: “ROOFTOP” indicates that the returned result is a precise geocode for which we have location information accurate down to street address precision. “RANGE_INTERPOLATED” indicates that the returned result reflects an approximation (usually on a road) interpolated between two precise points (such as intersections). Interpolated results are generally returned when rooftop geocodes are unavailable for a street address. “GEOMETRIC_CENTER” indicates that the returned result is the geometric center of a result such as a polyline (for example, a street) or polygon (region). “APPROXIMATE” indicates that the returned result is approximate.&quot; What this tells us is that Google believes it has reached rooftop accuracy for 2155 records but has selected the geometric centre or an approximate value for around 58% of the entries. Lets take a closer look at the geometric center data. results_complete %&gt;% filter(location_type == &quot;GEOMETRIC_CENTER&quot;) %&gt;% select(locations, lat, lng, formatted_address) ## # A tibble: 1,848 x 4 ## locations lat lng formatted_address ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 AAHRI, Bangkok, Tha… 13.8 101. 50, กรมประมง, ถนนพหลโยธิน, ลาดยาว จ… ## 2 Aarhus Univ Hosp, A… 56.2 10.2 Nørrebrogade, 8000 Aarhus, Denmark ## 3 Abasyn Univ, Peshaw… 34.0 71.6 Ring Road, Charsadda Link، Near Pat… ## 4 Abdul Wali Khan Uni… 34.2 72.0 Nowshera Mardan Rd, Muslimabad, Mar… ## 5 Abertay Univ, Dunde… 56.5 -2.97 Bell St, Dundee DD1 1HG, UK ## 6 Aberystwyth Univ, C… 52.4 -4.07 Penglais Campus, Penglais, Aberystw… ## 7 Aberystwyth Univ, D… 52.4 -4.07 Penglais Campus, Penglais, Aberystw… ## 8 ABRII, Karaj, Iran 35.8 51.0 Karaj, Alborz Province, Iran ## 9 Absyn Univ Peshawar… 34.0 71.6 Ring Road, Charsadda Link، Near Pat… ## 10 Acad Ciencias Cuba,… 23.1 -82.4 Havana, Cuba ## # ... with 1,838 more rows A review of these results suggests that the geometric center data is pretty good. In the past we might have ended up in a different country. But what about the approximate results? results_complete %&gt;% filter(location_type == &quot;APPROXIMATE&quot;) %&gt;% select(locations, lat, lng, formatted_address) ## # A tibble: 1,195 x 4 ## locations lat lng formatted_address ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Acad Sci Czech Republic, Brno, … 49.2 16.6 Brno, Czechia ## 2 Acad Sci Czech Republic, Ceske … 49.0 14.5 Ceske Budejovice, Czec… ## 3 Acad Sinica, Beijing, Peoples R… 39.9 116. Beijing, China ## 4 Achva Acad Coll, Mobile Post Sh… 31.7 34.6 Shikmim, Ashkelon, Isr… ## 5 ADAS UK Ltd, Cambs, England 52.2 0.122 Cambridgeshire, UK ## 6 Adv Choice Econ Pty Ltd, Batema… -25.3 134. Australia ## 7 AFRIMS Entomol Lab, Kamphaeng P… 16.5 99.5 Kamphaeng Phet, Thaila… ## 8 Agcy Consultat &amp; Res Oceanog, L… 45.2 1.97 19320 La Roche-Canilla… ## 9 Agcy Marine &amp; Fisheries Res Ind… -6.18 107. Jakarta, Indonesia ## 10 Agcy Marine &amp; Fisheries Res, Ja… -6.18 107. Jakarta, Indonesia ## # ... with 1,185 more rows The approximate results are a mixed bag, in some cases the coordinates focus on a city or town. In other cases such as Adv Choice Econ Pty Ltd, Bateman, Australia the coordinate is for a country and so on. 7.3 Preprocess the Data and Rerun the Query This suggests to me at least that while the geocoding is OK the prevalence of geometric centre and approximate results suggests that we might want to run this again but this time edit the location names first to see if we can improve the accuracy of the results. We now know that we can geocode pretty much all of this data. What we are interested in now is whether we can improve the accuracy of the geocoding. # import data and separate out the organisation country and city into new columns affiliation2 &lt;- read_csv(&quot;https://github.com/wipo-analytics/data-handbook/raw/master/affiliation_records.csv&quot;) %&gt;% separate(locations, c(&quot;organisation&quot;, &quot;city&quot;, &quot;country&quot;), sep = &quot;,&quot;, remove = FALSE) # import abbreviations wos_abbreviations &lt;- read_csv(&quot;https://github.com/wipo-analytics/data-handbook/raw/master/wos_abbreviations.csv&quot;, col_types = cols(abbreviation = col_character(), text = col_character())) # function to replace the abbreviations replaceabbr &lt;- function(pattern, replacement, var) { replacement &lt;- rep(replacement, length(pattern)) for (i in seq_along(pattern)) { var &lt;- gsub(pattern[i], replacement[i], var) } var } # regularise organisation names affiliation2 &lt;- affiliation2 %&gt;% mutate(organisation_edited = str_to_title(.$organisation)) %&gt;% mutate(city = str_to_title(.$city)) %&gt;% # added mutate(country = str_to_title(.$country)) #added # fix abbreviations affiliation2$organisation_edited &lt;- replaceabbr(wos_abbreviations$regex, wos_abbreviations$text, affiliation2$organisation_edited) # unite cleaned up fields affiliation2 &lt;- affiliation2 %&gt;% unite(., locations_edited, c(organisation_edited, city, country), sep = &quot;,&quot;, remove = FALSE) # run the search run1 &lt;- placement::geocode_url(affiliation2$locations_edited, auth = &quot;standard_api&quot;, privkey = key, clean = TRUE, add_date = &#39;today&#39;, verbose = TRUE) # drop the input-url and rename for join run1 &lt;- run1 %&gt;% select(-8) %&gt;% rename(locations_edited = locations) # join to the input table res_complete &lt;- left_join(affiliation2, run1, by = &quot;locations_edited&quot;) res_complete &lt;- res_complete %&gt;% mutate(duplicate_id = duplicated(id)) %&gt;% filter(duplicate_id == &quot;FALSE&quot;) When we join the two tables together we discover that we arrive at 5232 rather than 5,206 results. The reason for this is that the name harmonisation has created duplicated names from formerly distinct names. The Google API returns duplicate entries in these cases. These duplicate entries have been filtered out above. We will come on to other forms of duplication below. Ok let’s take a look at our results to assess whether this is an improvement. run1 %&gt;% drop_na(location_type) %&gt;% count(location_type, sort = TRUE) %&gt;% mutate(prop = prop.table(n)) ## # A tibble: 3 x 3 ## location_type n prop ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 ROOFTOP 2280 0.439 ## 2 GEOMETRIC_CENTER 1927 0.371 ## 3 APPROXIMATE 981 0.189 What this has done is improved the rooftop resolution by a couple of percentage points and improved the geometric centre results by about the same. The approximate score has dropped to 19% from 23% so this is definitely progress. In total 214 records have moved up from the approximate to the rooftop or geometric centre location_types. As this suggests, improving the quality of geocoding matters and it is therefore worth putting the effort into improving the resolution of the results. 7.3.1 Duplicated Affiliation Names It will not have escaped your attention that in reality our original input data contained a significant amount of duplication on organisation names. This becomes obvious when we review the organisation edited field. We can rapidly see multiple entries. affiliation2 %&gt;% count(organisation_edited, sort = TRUE) ## # A tibble: 4,042 x 2 ## organisation_edited n ## &lt;chr&gt; &lt;int&gt; ## 1 University Putra Malaysia 19 ## 2 Chinese Academy Science 15 ## 3 Mahidol University 15 ## 4 Prince Songkla University 14 ## 5 University Philippines 14 ## 6 Cnrs 12 ## 7 Department Fisheries 12 ## 8 Fisheries Research Agency 12 ## 9 Indonesian Institute Science 12 ## 10 Ministry Health 12 ## # ... with 4,032 more rows There are a number of reasons for this. In some cases researchers may list different departments or institutes along with the name of their organisation. In other cases an organisation (such as the Chinese Academy of Science or CNRS) may have multiple offices within or outside a particular country. In still other cases, such as Department Fisheries or Ministry Health we are lumping together organisations that share the same name but are distinct entities. Lets take a closer look at this. affiliation2 %&gt;% select(locations, organisation_edited) %&gt;% head(20) ## # A tibble: 20 x 2 ## locations organisation_edited ## &lt;chr&gt; &lt;chr&gt; ## 1 AAHL, Vic, Australia Aahl ## 2 AAHRI, Bangkok, Thailand Aahri ## 3 Aarhus Univ Biosci, Roskilde, Denmark Aarhus University Bioscience ## 4 Aarhus Univ Hosp, Aarhus, Denmark Aarhus University Hospital ## 5 Aarhus Univ, Aarhus C, Denmark Aarhus University ## 6 Aarhus Univ, Aarhus, Denmark Aarhus University ## 7 Abasyn Univ, Peshawar, Pakistan Abasyn University ## 8 Abdul Wali Khan Univ, Mardan, Pakistan Abdul Wali Khan University ## 9 Abertay Univ, Dundee DD1 1HG, Scotland Abertay University ## 10 Aberystwyth Univ, Ceredigion, Wales Aberystwyth University ## 11 Aberystwyth Univ, Dyfed, Wales Aberystwyth University ## 12 Abo Akad Univ, Turku, Finland Abo Akad University ## 13 ABRII, Karaj, Iran Abrii ## 14 Absyn Univ Peshawar, Peshawar, Pakistan Absyn University Peshawar ## 15 Acad Ciencias Cuba, C Habana, Cuba Academy Ciencias Cuba ## 16 Acad Nat Sci Philadelphia, Philadelphia,… Academy Natural Science Phil… ## 17 Acad Sci Czech Republ, Ceske Budejovice,… Academy Science Czech Republ ## 18 Acad Sci Czech Republic, Brno, Czech Rep… Academy Science Czech Republ… ## 19 Acad Sci Czech Republic, Ceske Budejovic… Academy Science Czech Republ… ## 20 Acad Sci Czech Republic, Prague, Czech R… Academy Science Czech Republ… In the case of Aarhus University, we can see that we have Aarhus University Bioscience, Aarhus University Hospital and an Aarhus University. In some cases the entities belong to the organisation but might otherwise be regarded as distinct (Aarhus University Hospital) while in another the Bioscience reference refers to a department (but gives the impression that it may be a separate University as for Agricultural cases). To add to this we note that there are locations in Aarhus and Roskilde and a minor variant (Aarhus C) in the address field. As this makes clear address field data in scientific names is pretty messy because authors choose how to denote their affiliations, and are perhaps rebelling against the tyranny of performance indicators and endless research assessment exercises. Cleaning up author affiliation and author names is generally a painful process (and we will come back to this in a future article). One challenge with name cleaning is the availability of criteria to determine if a name can be merged. For example, we could comfortably merge some of the Aarhus University references above but we might want to keep distinct locations distinct (for example Aarhus is around 150km by road from Roskilde). The availability of georeferenced data, bearing in mind the approximates issue, could provide us with additional information for informed decision making during name cleaning. Let’s take a quick look at the formatted address field in our results. res_complete %&gt;% select(formatted_address, organisation_edited) %&gt;% head(20) ## # A tibble: 20 x 2 ## formatted_address organisation_edited ## &lt;chr&gt; &lt;chr&gt; ## 1 5 Portarlington Road, Newcomb VIC 3219, Aus… Aahl ## 2 50, กรมประมง, ถนนพหลโยธิน, ลาดยาว จตุจักร B… Aahri ## 3 Aarhus University, 150, Frederiksborgvej 39… Aarhus University Bioscie… ## 4 Nørrebrogade, 8000 Aarhus, Denmark Aarhus University Hospital ## 5 Langelandsgade 140, 8000 Aarhus, Denmark Aarhus University ## 6 Langelandsgade 140, 8000 Aarhus, Denmark Aarhus University ## 7 Ring Road, Charsadda Link، Near Patang Chow… Abasyn University ## 8 Nowshera Mardan Rd, Muslimabad, Mardan, Khy… Abdul Wali Khan University ## 9 Bell St, Dundee DD1 1HG, UK Abertay University ## 10 Penglais Campus, Penglais, Aberystwyth SY23… Aberystwyth University ## 11 Penglais Campus, Penglais, Aberystwyth SY23… Aberystwyth University ## 12 Domkyrkotorget 3, 20500 Åbo, Finland Abo Akad University ## 13 Karaj, Alborz Province, Iran Abrii ## 14 Ring Road, Charsadda Link، Near Patang Chow… Absyn University Peshawar ## 15 Havana, Cuba Academy Ciencias Cuba ## 16 1900 Benjamin Franklin Pkwy, Philadelphia, … Academy Natural Science P… ## 17 Branišovská 1645/31A, České Budějovice 2, 3… Academy Science Czech Rep… ## 18 Palackého tř. 1946/1, 612 42 Brno-Královo P… Academy Science Czech Rep… ## 19 Branišovská 1645/31A, České Budějovice 2, 3… Academy Science Czech Rep… ## 20 Žitná 609/25, 110 00 Praha-Nové Město, Czec… Academy Science Czech Rep… Here we can see that the Google data suggests that some of these entities share an address. Based on this we may want (with appropriate attention to the location type field as a guide) to merge or not merge names in our list. If we take a look at the counts for shared addresses it becomes clear that we may want to use a step wise approach depending on the level of confidence in the location type field. res_complete %&gt;% filter(location_type == &quot;ROOFTOP&quot;) %&gt;% count(formatted_address, sort = TRUE) ## # A tibble: 1,653 x 2 ## formatted_address n ## &lt;chr&gt; &lt;int&gt; ## 1 113 Soi Klong Luang 17, Tambon Khlong Nung, Amphoe Khlong Luang,… 16 ## 2 18 Hoàng Quốc Việt, Nghĩa Đô, Cầu Giấy, Hà Nội, Vietnam 14 ## 3 169 Long Had Bangsaen Rd, Tambon Saen Suk, อำเภอ เมืองชลบุรี Cha… 11 ## 4 15 Karnjanavanit Soi 7 Rd, Kho Hong, Amphoe Hat Yai, Chang Wat S… 9 ## 5 999 Phutthamonthon Sai 4 Rd, Tambon Salaya, Amphoe Phutthamontho… 9 ## 6 Jl. Pasir Putih Raya No.1, RT.8/RW.10, Kota Tua, Pademangan Tim.… 9 ## 7 New Administration Building, Miagao, 5023 Iloilo, Philippines 9 ## 8 02 Nguyễn Đình Chiểu, Vĩnh Thọ, Thành phố Nha Trang, Vĩnh Thọ Th… 8 ## 9 Nørregade 10, 1165 København, Denmark 8 ## 10 Pesthuislaan 7, 2333 BA Leiden, Netherlands 8 ## # ... with 1,643 more rows 7.3.2 Quickly Mapping the Data To finish off lets quickly map the data. We will focus on mapping in more detail in other articles in the Handbook. For the moment we will use the leaflet package for this. install.packages(&quot;leaflet&quot;) library(leaflet) ## ## Attaching package: &#39;leaflet&#39; ## The following object is masked from &#39;package:networkD3&#39;: ## ## JS mapdata &lt;- res_complete %&gt;% filter(., status == &quot;OK&quot;) mapdata &lt;- leaflet(mapdata) %&gt;% addTiles() %&gt;% addCircleMarkers(~lng, ~lat, popup = .$locations_edited, radius = mapdata$records / 20, weight = 0.1, opacity = 0.2, fill= TRUE, fillOpacity = 0.2) mapdata As this makes clear it is relatively straightforward to generate quick maps with R and even easier to export the data to tools such as Tableau for publication quality and interactive maps. We will go into mapping in more depth in a future article. 7.4 Round Up In this article we looked at three R packages for geocoding data on research affiliations from the scientific literature using Web of Science. We focused on the use of the placement package as it is very easy to use. However, your needs may differ with packages such as ggmap and googleway offering different functionality. The main take away message is that geocoding using the Google Maps API will normally be an iterative process that may requires multiple passes and adjustments to the data to arrive at accurate results. One things should now also be clear, while the Google Maps API has dramatically improved in its ability to offer geocoded results (including on messy names) these results should not be taken at face value. Instead, and depending on your purpose, multiple iterations may be needed to improve the resolution of the results. In this article we have not gone all the way with this but have hopefully provided enough pointers to allow you to take it further. R is a functional programming language meaning that it will be feasible to construct a function that brings together the functions used to process the data in the above steps. We will not go there today, but to round up lets think about some of the elements that we might want to use to address this in a single R function based on the steps that we have taken above. import dataset address case issues separate organisation, city, country resolve abbreviations on organisation names unite organisation, city and country into a new field send the cleaned field to the API and retrieve results adjust column names to match join results to original review the location type adjust and rerun as needed to improve rooftop and geometric centre results vs. approximate results In many cases it will make sense to choose a threshold based on counts of records before sending the data to the API. For example where dealing with publications (as in this case) it could make sense to exclude records where there is only one record. For example, in our original input table 1,624 entries only had one record. If no one is ever likely to look at data points with only one record you may wish to filter them out and concentrate on the accuracy of geocoding for scores above the threshold. We have also seen that while the focus of geocoding is logically on mapping, in reality geocoding services may offer new opportunities for the vexed problem of accurate name cleaning when working with the scientific literature or patent data. We will look at this in more detail in a future article. For the moment, congratulations, you have survived geocoding using the Google Maps API in R. Reverse geocoding is the process of converting coordinates into named places but will not be covered in this chapter↩ If you would like to install qdap but run into problems with rjava on a Mac the instructions here can solve installation problems.↩ "],
["references.html", "Chapter 8 References", " Chapter 8 References "],
["machinelearning.html", "Chapter 9 Machine Learning (placeholder)", " Chapter 9 Machine Learning (placeholder) This is a placeholder, please come back later "],
["classification.html", "Chapter 10 Patent Classfication (placeholder)", " Chapter 10 Patent Classfication (placeholder) This is a placeholder, please come back later "],
["citations.html", "Chapter 11 Patent Citations (placeholder)", " Chapter 11 Patent Citations (placeholder) This is a placeholder, please come back later "],
["social.html", "Chapter 12 Social Media and Patent Analytics (placeholder)", " Chapter 12 Social Media and Patent Analytics (placeholder) This is a placeholder, please come back later "]
]
