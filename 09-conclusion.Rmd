# Conclusion {#conclusion}


This Handbook has aimed to provide an accessible and practical guide to intermediate and advanced methods and tools for patent analytics. The Handbook is a complement to the WIPO Manual on Open Source Patent Analytics that has been widely used in introductory training in patent analytics. 

In conclusion it is important to highlight some of the key take home messages that emerge from this wide ranging exploration of methods in patent analytics. 

The first of these is that patent activity is an outcome of underlying investments in Research and Development. When initiating research for a patent analytics project it makes very good sense to start by investigating the scientific literature. Analysis of the scientific literature not only contributes to the process of identifying search strategies for an area of technology but allows you to become familiar with the main trends and actors involved in a technology area. The growing accessibility of tools for geospatial mapping, such as APIs or the new Research Organization Registry (ROR) and its incorporation into datasets such as OpenAlex, means that it is now possible to rapidly generate useful maps of global research activity. Mapping of this type not only assists with refining the focus of an analytics project but can also assist with identifying potential partners in different countries around the world and competing or emerging approaches. Finally, research organisations are also increasingly important players in the global landscape of patent activity. For these reasons research methods involving the scientific literature are so prominent in this Handbook.

Our second main insight is that it is very important to become familiar with different methods for counting patent data and the purposes to which different types of count can be used. This also requires careful attention to terminology in order to avoid misleading an audience. For example, as a matter of good practice the use of the word patent documents to describe patent data rather than 'patents' avoids giving an audience the impression that the analysis refers to patent grants rather than applications or a mix of applications and grants. It is important to be clear with audiences about what is being described. For example, where the focus is on identifying trends in research and development the use of priority counts is appropriate and can be readily explained as first filings. An audience will then generally want to see trends in applications and grants which involves engagement with patent families and careful attention to kind codes and effective description. Because different data providers use different and sometimes opaque definitions of patent families it is logical to use the DOCDB or INPADOC families wherever possible. However, in all cases analysis of activity using patent family data should be clearly explained to the reader with added notes on issues around the interpretation of kind codes particularly where analysis is extended to multiple countries. Methodological transparency is critically important where analysis aims to inform commercial or policy decision making. 

A detailed understanding of the types and issues involved in patent counts is also important in preparation for modelling patent data. Chapter 4 introduced linear regression using widely used models for elucidating trends in existing data. This in turn provided a basis for the exploration of common approaches to forecasting using data on PCT applications at WIPO. As our example of a fictional crisis at WIPO made clear, it is possible to forecast patent activity such as PCT filings at WIPO. However, this requires an understanding both of the data itself and approaches to forecasting and their strengths and weaknesses. For example, we might reasonably feel confident in approaching forecasting of first filings in individual countries or areas of technology but forecasting patent family activity globally would be an entirely different matter. In making the transition from simple counts to modelling patent activity we can readily use common smoothing models but forecasting requires considerable care in selecting the data to be forecast.

The global patent system can be likened to the fictional Hogwarts library in that the global patent library houses information that is entirely innocuous and information that could be dangerous in the wrong hands. Knowledge of patent classification systems is central to the ability of an analyst to successfully navigate this system. It is therefore important to recognise the strength of patent classification systems in helping to focus patent analysis by selecting relevant areas of the system. However, as we saw in the case study in Chapter 5 it is also important to recognise the weaknesses of the patent classification for specific projects. Thus, while useful, the classification will commonly be either too broad or too specific for a specific analytics project. In other cases, such as emerging technologies, the classification may not yet have caught up with the latest developments (e.g. in the historic case nanotechnology). These limitations will generally require patent analysts to develop their own groupings. Chapter 5 provided an example of one approach to grouping using network analysis and community detection that became the basis for organising a patent landscape analysis. Finally, it is important to remember that the use of classification in patent analysis forms part of an exercise in communication with an audience who are unlikely to have much time, or be interested in classification symbols or long reams of formulaic text. As such, finding ways to communicate data on technology areas in a way that is understandable, as in the case of the short IPC, is an important element in successful patent analytics. 

Citation analysis has been a major if not foundational focus of attention in scientometrics and patent analytics. Chapter 6 provided an in depth exploration of patent citations using the example of Nobel prize winning gene editing (CRISPR) technology and the contest between Berkeley and the Broad Institute in this field. Analysis of this worked example provided a basis for the exploration of main path analysis that combines citation analysis with the use of patent classification systems in order to reveal the development of technologies and point towards the forecasting and detection of technological trajectories. Patent citation data is increasingly available at scale through the OECD, the US PatentsView and web services such as the Lens patent API. In addition, the citation connections between the scientific and patent literature are also increasingly openly accessible at a range of different scales to inform patent analytics. Citation analysis is a critically important part of patent analysis because it allows us to identify the contours of technology landscapes using the framework of patent classification systems and increasingly to identify the trajectories of technologies within those landscapes. In future years, the ability to freely access citation data at scale will in the author's view provide a platform for transformations in the scale and accuracy of patent analytics. 

Text mining is a key component of patent analytics and is being transformed by growing access to full text patent data thanks to the work of the USPTO PatentsView service and the EPO. Growing access to patent texts at scale is also accompanied by the increasing accessibility of machine learning based approaches to Natural Language Processing (NLP). Chapter 7 examined standard widely used approaches to text mining and demonstrated how text mining could be combined with knowledge of the patent classification to more accurately target texts. Using the worked example of biodiversity patent activity this provided a basis for the analysis of words and phrases (ngrams) in text mining and widely used technique such as Term Frequency Inverse Document Frequency (TFIDF) to identify the distinctive features of texts in areas of the classification and to focus the analysis on areas such as gene editing. The Chapter also demonstrated the analysis of terms over time and the role of the visualisation of networks of terms in patent analytics. These common techniques can be applied either programmatically (e.g. using R or Python) or using specialised analytics software such as VantagePoint for fine grained control. 

Standard approaches to text mining are extremely effective for many patent analytics tasks either using R, Python or VantagePoint. However, these approaches are increasingly being complemented and for some replaced by machine learning based approaches to Natural Language Processing. Chapter 8 provided an in depth introduction to machine learning as a field that encompasses Natural Language Processing, text classification, named entity recognition and image classification. Machine learning based approaches to text or image analysis are ultimately based on the use of algorithms to recognise patterns. Chapter 8 provided an in depth exploration of machine learning in Natural Language Processing using the fasttext, spaCy and Prodigy libraries. The Chapter concluded by pointing to the increasing accessibility of more accurate transformer models and off the shelf plug and play services provided through companies such as HuggingFace and the major cloud service providers. 

For patent analytics the promise of machine learning based approaches is that it will be possible to automate tasks such as classification and entity recognition at scale and incorporate models into processing pipelines. The growing accessibility of pretrained models and affordable infrastructure means that these approaches will become increasingly accessible for analysts regardless of their budgets. Above all, the promise of machine learning approaches for text analysis tasks is that it will relieve some of the burden of hard manual processing from the analyst through automation. However, as discussed in Chapter 8 against this we must not underestimate the challenge of training models to perform accurately on the specialised language of patent texts or the images that accompany patents. In machine learning, the quality of training data is king. A great deal of hidden time and labour is required to generate training data that is appropriate for patent analytics. We may hope, as some initiatives already suggest, that with time specialised models will be created to assist with the classification and extraction of entities from patent documents. However, in the meantime patent analysts will be wise to rely on existing easy to use techniques and to progressively experiment with incorporating accessible machine learning models into their workflows. In this way patent analysts can benefit from the undoubted strengths of machine learning approaches while avoiding some of its pitfalls. 

In closing the Handbook it is appropriate to briefly speculate about what the future of patent analytics might look like. For the author of this Handbook it would be highly desirable to see the increasing availability of patent data in forms that are amenable for patent analytics. The USPTO PatentsView service is the model in this regard followed by the EPO. It is to be hoped that in future the WIPO PCT collection might also be made available. As we have seen in the Handbook considerable manual or computational processing is required on the part of analysts, notably with data cleaning and text processing. Some of this work could be done in advance such as the harmonisation of applicant and inventor names. The OECD has done pioneering work in this area that is linked to work the EPO World Patent Statistical Database (PATSTAT). More recently the USPTO PatentsView service has done admirable work in disambiguating applicant and inventor names and geocoding patent data. It is highly desirable to support and encourage these types of initiatives for the benefit of the wider users of patent data. At the same time we could imagine that a great deal of the hard labour in text based patent analytics could be removed by following the example of the [General Index](https://archive.org/details/GeneralIndex) which provides open access to the ngrams of over 57 million scientific articles. A similar initiative by patent offices with their texts could greatly improve the access of patent texts for analytics purposes by wider user communities. In a similar vein, as we saw in the example of fasttext, supporting and perhaps maintaining vector space models could greatly reduce duplication of effort by creating a common baseline. This would allow researchers and commercial providers to focus on the development of more specialist tasks.

Finally, as the first Handbook of its type the present work forms part of a wider effort to promote open patent analytics for the benefit of the wider community. I hope that the Handbook has proved useful and that you will contribute through your own work to the promotion of open patent analytics for the benefit of the wider community.
